{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cdeeff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live         0.0  \n",
       "1  Communicating data science: A guide to present...       Live         1.0  \n",
       "2         This Week in Data Science (April 18, 2017)       Live         2.0  \n",
       "3  DataLayer Conference: Boost the performance of...       Live         3.0  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live         4.0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import project_tests as t\n",
    "import pickle\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Import the tokenize function from tokenize_mod\n",
    "from tokenize_mod import tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# Show df to get an idea of the data\n",
    "# This data set includes the articles with title and email per \"view\"\n",
    "df_content['article_id'] = df_content['article_id'].astype(float)\n",
    "df_content = df_content.drop_duplicates(subset=\"article_id\")\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ee709f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_articles(df, df_content):\n",
    "    \"\"\"\n",
    "    This function checks if there are any article_ids in df that are not in df_content.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): The main DataFrame with article interactions.\n",
    "    df_content (DataFrame): The DataFrame containing article metadata.\n",
    "    \n",
    "    Returns:\n",
    "    missing_article_ids (list): A list of article_ids in df that are not present in df_content.\n",
    "    \"\"\"\n",
    "    # Convert article_id columns to string to avoid data type mismatch\n",
    "    df['article_id'] = df['article_id'].astype(str)\n",
    "    df_content['article_id'] = df_content['article_id'].astype(str)\n",
    "\n",
    "    # Find article_ids in df that are not in df_content\n",
    "    missing_article_ids = df[~df['article_id'].isin(df_content['article_id'])]['article_id'].unique()\n",
    "\n",
    "    # Return the list of missing article_ids\n",
    "    return missing_article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9dd53a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_articles = find_missing_articles(df, df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a2ef91b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1444.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.article_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8803e8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050.0"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.article_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "583126f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_name = df_content.doc_full_name.values.tolist()\n",
    "len(doc_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30ac71bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['detect', 'malfunctioning', 'iot', 'sensors', 'streaming', 'analytics'],\n",
       " ['communicating', 'data', 'science', 'a', 'guide', 'presenting', 'work'],\n",
       " ['this', 'week', 'data', 'science', 'april', '18', '2017'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'boost',\n",
       "  'performance',\n",
       "  'distributed',\n",
       "  'database'],\n",
       " ['analyze', 'ny', 'restaurant', 'data', 'using', 'spark', 'dsx'],\n",
       " ['browsing', 'postgresql', 'data', 'compose'],\n",
       " ['upgrading', 'postgresql', '9', '5'],\n",
       " ['data', 'wrangling', 'slack'],\n",
       " ['data', 'science', 'bowl', '2017'],\n",
       " ['using',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'predict',\n",
       "  'attack',\n",
       "  'vector',\n",
       "  'among',\n",
       "  'billion',\n",
       "  'user',\n",
       "  'trillion',\n",
       "  'event'],\n",
       " ['offline',\n",
       "  'first',\n",
       "  'ios',\n",
       "  'apps',\n",
       "  'swift',\n",
       "  'cloudant',\n",
       "  'sync',\n",
       "  'part',\n",
       "  '1',\n",
       "  'the',\n",
       "  'datastore'],\n",
       " ['warehousing', 'geojson', 'document'],\n",
       " ['timeseries',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'iot',\n",
       "  'event',\n",
       "  'using',\n",
       "  'jupyter',\n",
       "  'notebook'],\n",
       " ['bridging', 'gap', 'between', 'python', 'scala', 'jupyter', 'notebooks'],\n",
       " ['got',\n",
       "  'zip',\n",
       "  'code',\n",
       "  'data',\n",
       "  'prep',\n",
       "  'analytics',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['apache',\n",
       "  'spark',\n",
       "  '2',\n",
       "  '0',\n",
       "  'extend',\n",
       "  'structured',\n",
       "  'streaming',\n",
       "  'spark',\n",
       "  'ml'],\n",
       " ['higher', 'order', 'logistic', 'regression', 'large', 'datasets'],\n",
       " ['compose', 'mysql'],\n",
       " ['the', 'greatest', 'public', 'datasets', 'ai', 'startup', 'grind'],\n",
       " ['finding', 'mode', 'postgresql'],\n",
       " ['working', 'interactively', 'rstudio', 'notebook', 'dsx'],\n",
       " ['mapping',\n",
       "  'data',\n",
       "  'science',\n",
       "  'pixiedust',\n",
       "  'mapbox',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['move', 'csvs', 'different', 'json', 'doc', 'store'],\n",
       " ['tutorial', 'how', 'build', 'query', 'cloudant', 'geospatial', 'index'],\n",
       " ['the', 'conversational', 'interface', 'new', 'paradigm'],\n",
       " ['creating', 'data', 'science', 'experience'],\n",
       " ['using', 'machine', 'learning', 'predict', 'parking', 'difficulty'],\n",
       " ['getting', 'the', 'best', 'performance', 'with', 'pyspark'],\n",
       " ['deep',\n",
       "  'forest',\n",
       "  'towards',\n",
       "  'an',\n",
       "  'alternative',\n",
       "  'deep',\n",
       "  'neural',\n",
       "  'networks'],\n",
       " ['experience', 'iot', 'coursera'],\n",
       " ['how',\n",
       "  'open',\n",
       "  'api',\n",
       "  'economy',\n",
       "  'accelerates',\n",
       "  'growth',\n",
       "  'big',\n",
       "  'data',\n",
       "  'analytics'],\n",
       " ['sign', 'free', 'trial', 'dsx'],\n",
       " ['a', 'kaggler', 'guide', 'model', 'stacking', 'practice'],\n",
       " ['using', 'brunel', 'ipython', 'jupyter', 'notebooks'],\n",
       " ['top', '10', 'machine', 'learning', 'use', 'cases', 'part', '1'],\n",
       " ['gaze',\n",
       "  'into',\n",
       "  'my',\n",
       "  'reddit',\n",
       "  'crystal',\n",
       "  'ball',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['data', 'visualization', 'playbook', 'the', 'right', 'level', 'detail'],\n",
       " ['create',\n",
       "  'custom',\n",
       "  'domain',\n",
       "  'cloudant',\n",
       "  'using',\n",
       "  'cloudflare',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['for', 'developers', 'querying', 'cloudant', 'primary', 'index'],\n",
       " ['pulling', 'displaying', 'etf', 'data'],\n",
       " ['ensemble', 'learning', 'improve', 'machine', 'learning', 'results'],\n",
       " ['customizing', 'mongodb', 'shell', 'compact', 'prompts'],\n",
       " ['getting', 'started', 'compose', 'scylladb'],\n",
       " ['deep',\n",
       "  'learning',\n",
       "  'with',\n",
       "  'tensorflow',\n",
       "  'course',\n",
       "  'big',\n",
       "  'data',\n",
       "  'university'],\n",
       " ['uncover', 'product', 'insights', 'hidden', 'stack', 'overflow'],\n",
       " ['start', 'developing', 'spark', 'notebooks'],\n",
       " ['q', 'a', 'voting', 'app', 'rethinkdb'],\n",
       " ['install', 'ibm', 'database', 'conversion', 'workbench'],\n",
       " ['data', 'science', 'experience', 'documentation'],\n",
       " ['geofile',\n",
       "  'using',\n",
       "  'openstreetmap',\n",
       "  'data',\n",
       "  'compose',\n",
       "  'postgresql',\n",
       "  'part',\n",
       "  'ii'],\n",
       " ['graph', 'based', 'machine', 'learning'],\n",
       " ['modern', 'machine', 'learning', 'algorithms'],\n",
       " ['build', 'app', 'using', 'ibm', 'graph'],\n",
       " ['introducing', 'streams', 'designer'],\n",
       " ['8',\n",
       "  'way',\n",
       "  'turn',\n",
       "  'data',\n",
       "  'value',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'machine',\n",
       "  'learning'],\n",
       " ['predict',\n",
       "  'flight',\n",
       "  'delays',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'mllib',\n",
       "  'flightstats',\n",
       "  'weather',\n",
       "  'data'],\n",
       " ['introducing', 'simple', 'autocomplete', 'service'],\n",
       " ['transfer',\n",
       "  'learning',\n",
       "  'flight',\n",
       "  'delay',\n",
       "  'prediction',\n",
       "  'via',\n",
       "  'variational',\n",
       "  'autoencoders'],\n",
       " ['advancements', 'spark', 'community'],\n",
       " ['how',\n",
       "  'tame',\n",
       "  'valley',\n",
       "  'hessian',\n",
       "  'free',\n",
       "  'hack',\n",
       "  'optimizing',\n",
       "  'large',\n",
       "  'neuralnetworks',\n",
       "  'autonomous',\n",
       "  'agents',\n",
       "  'ai'],\n",
       " ['readr', '1', '0', '0'],\n",
       " ['metrics', 'maven', 'window', 'functions', 'postgresql'],\n",
       " ['data',\n",
       "  'visualization',\n",
       "  'the',\n",
       "  'importance',\n",
       "  'excluding',\n",
       "  'unnecessary',\n",
       "  'detail'],\n",
       " ['compose', 'postgresql', 'making', 'user'],\n",
       " ['predicting', 'gentrification', 'using', 'longitudinal', 'census', 'data'],\n",
       " ['interconnect', 'u'],\n",
       " ['introducing', 'cloudant', 'foodtracker', 'an', 'offline', 'first', 'app'],\n",
       " ['find', 'mongo', 'document', 'by', 'id', 'using', 'the', 'php', 'library'],\n",
       " ['an',\n",
       "  'introduction',\n",
       "  'scientific',\n",
       "  'python',\n",
       "  'bit',\n",
       "  'maths',\n",
       "  'behind',\n",
       "  'it',\n",
       "  'numpy'],\n",
       " ['metrics', 'maven', 'calculating', 'moving', 'average', 'postgresql'],\n",
       " ['offline', 'first', 'apps', 'pouchdb'],\n",
       " ['simple',\n",
       "  'metrics',\n",
       "  'tutorial',\n",
       "  'part',\n",
       "  '1',\n",
       "  'metrics',\n",
       "  'collection',\n",
       "  'code',\n",
       "  'web',\n",
       "  'analytics',\n",
       "  'app',\n",
       "  'node',\n",
       "  'j',\n",
       "  'ibm',\n",
       "  'cloudant'],\n",
       " ['could', 'postgresql', '9', '5', 'next', 'json', 'database'],\n",
       " ['this', 'week', 'data', 'science', 'september', '27', '2016'],\n",
       " ['the', '3', 'kinds', 'context', 'machine', 'learning', 'art', 'frame'],\n",
       " ['tour', 'community', 'dsx'],\n",
       " ['this', 'week', 'data', 'science', 'may', '2', '2017'],\n",
       " ['apache', 'spark', 'scale', 'a', '60', 'tb', 'production', 'use', 'case'],\n",
       " ['this', 'week', 'data', 'science', 'may', '16', '2017'],\n",
       " ['tutorial', 'how', 'cloudant', 'geospatial', 'action'],\n",
       " ['leverage', 'scikit', 'learn', 'models', 'core', 'ml'],\n",
       " ['transform', 'anything', 'vector'],\n",
       " ['build', 'logistic', 'regression', 'model', 'wml', 'dsx'],\n",
       " ['compose', 'first', 'graph', 'database', 'janusgraph'],\n",
       " ['tutorial', 'how', 'load', 'twitter', 'data', 'ibm', 'dashdb'],\n",
       " ['testthat', '1', '0', '0'],\n",
       " ['metrics', 'maven', 'beyond', 'average'],\n",
       " ['this', 'week', 'data', 'science', 'july', '26', '2016'],\n",
       " ['simple', 'metrics', 'collector', 'microservices', 'edition'],\n",
       " ['top', '20', 'r', 'machine', 'learning', 'data', 'science', 'package'],\n",
       " ['new', 'import', 'compose', 'mongodb'],\n",
       " ['website', 'engagement', 'tracking', 'elasticsearch'],\n",
       " ['9',\n",
       "  'mistakes',\n",
       "  'avoid',\n",
       "  'when',\n",
       "  'starting',\n",
       "  'your',\n",
       "  'career',\n",
       "  'data',\n",
       "  'science'],\n",
       " ['deploy', 'your', 'php', 'application', 'bluemix'],\n",
       " ['armand',\n",
       "  'ruiz',\n",
       "  'gabernet',\n",
       "  'ibm',\n",
       "  'bigdatanyc',\n",
       "  'bigdatanyc',\n",
       "  '2016',\n",
       "  'thecube'],\n",
       " ['this', 'week', 'data', 'science', 'december', '20', '2016'],\n",
       " ['improving', 'quality', 'life', 'spark', 'empowered', 'machine', 'learning'],\n",
       " ['this', 'week', 'data', 'science', 'november', '08', '2016'],\n",
       " ['how', 'map', 'usa', 'river', 'using', 'ggplot2'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '2', 'mongodb'],\n",
       " ['use', 'data', 'asset', 'project', 'using', 'ibm', 'data', 'catalog'],\n",
       " ['how', 'choose', 'project', 'practice', 'data', 'science'],\n",
       " ['how', 'ease', 'strain', 'data', 'volume', 'rise'],\n",
       " ['how', 'scale', 'your', 'analytics', 'using', 'r'],\n",
       " ['this', 'week', 'data', 'science', 'november', '15', '2016'],\n",
       " ['building', 'offline', 'first', 'progressive', 'web', 'apps'],\n",
       " ['data', 'visualization', 'function', 'drive', 'design'],\n",
       " ['when', 'machine', 'learning', 'matter', 'erik', 'bernhardsson'],\n",
       " ['using',\n",
       "  'notebooks',\n",
       "  'pixiedust',\n",
       "  'fast',\n",
       "  'flexible',\n",
       "  'easier',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'experimentation'],\n",
       " ['tensorflow', 'quick', 'tips'],\n",
       " ['pixiedust', 'magic', 'your', 'python', 'notebook'],\n",
       " ['tidy', 'jupyter', 'notebook', 'script'],\n",
       " ['building',\n",
       "  'custom',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'with',\n",
       "  'apache',\n",
       "  'systemml'],\n",
       " ['this', 'week', 'data', 'science', 'february', '28', '2017'],\n",
       " ['use', 'databases'],\n",
       " ['finding', 'user', 'data', 'science'],\n",
       " ['practical', 'tutorial', 'random', 'forest', 'parameter', 'tuning', 'r'],\n",
       " ['apache', 'spark', '2', '0', 'migrating', 'applications'],\n",
       " ['making', 'most', 'compose', 'customer', 'one', 'preschool'],\n",
       " ['launch', 'spark', 'job', 'using', 'spark', 'submit'],\n",
       " ['a', 'dynamic', 'duo', 'inside', 'machine', 'learning', 'medium'],\n",
       " ['picking', 'sql', 'nosql', 'a', 'compose', 'view'],\n",
       " ['watson', 'machine', 'learning', 'developers'],\n",
       " ['what', 'hoopla', 'graph', 'database'],\n",
       " ['python', 'machine', 'learning', 'scikit', 'learn', 'tutorial'],\n",
       " ['statistics', 'hackers'],\n",
       " ['rethinkdb', 'joinery'],\n",
       " ['cloudant', 'meteor', 'couchdb'],\n",
       " ['search', 'faceting', 'scratch', 'tutorial'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'translating',\n",
       "  'backend',\n",
       "  'data',\n",
       "  'frontend',\n",
       "  'needs'],\n",
       " ['feature', 'importance', 'important'],\n",
       " ['simple', 'graphing', 'ipython', 'pandas'],\n",
       " ['collecting', 'data', 'science', 'cheat', 'sheets'],\n",
       " ['how', 'script', 'painless', 'ly', 'elasticsearch'],\n",
       " ['this', 'week', 'data', 'science', 'november', '01', '2016'],\n",
       " ['simple', 'couchdb', 'cloudant', 'backup'],\n",
       " ['this', 'week', 'data', 'science', 'february', '7', '2017'],\n",
       " ['execute', 'common', 'http', 'api', 'commands'],\n",
       " ['best', 'package', 'data', 'manipulation', 'r'],\n",
       " ['designing', 'ufc', 'moneyball'],\n",
       " ['emile', 'baizel', 'building', 'fintech', 'bot', 'mongodb', 'elasticsearch'],\n",
       " ['reddit', 'sentiment', 'analysis', 'sparkr', 'couchdb'],\n",
       " ['neural', 'network', 'beginner', 'popular', 'type', 'application'],\n",
       " ['0',\n",
       "  'life',\n",
       "  'changing',\n",
       "  'app',\n",
       "  'scala',\n",
       "  'first',\n",
       "  'steps',\n",
       "  'interview',\n",
       "  'jakob',\n",
       "  'odersky'],\n",
       " ['this', 'week', 'data', 'science', 'july', '12', '2016'],\n",
       " ['don',\n",
       "  'throw',\n",
       "  'data',\n",
       "  'problem',\n",
       "  'here',\n",
       "  'unlock',\n",
       "  'true',\n",
       "  'value',\n",
       "  'data',\n",
       "  'lake'],\n",
       " ['how',\n",
       "  'use',\n",
       "  'db2',\n",
       "  'warehouse',\n",
       "  'cloud',\n",
       "  'data',\n",
       "  'science',\n",
       "  'experience',\n",
       "  'notebook'],\n",
       " ['offline', 'first', 'qr', 'code', 'badge', 'scanner'],\n",
       " ['search', 'slack', 'ibm', 'graph'],\n",
       " ['ibm', 'cd', 'lab', 'hybrid', 'cloud', 'tutorial'],\n",
       " ['campus', 'discounts', 'making', 'most', 'compose', 'customer'],\n",
       " ['jupyter', 'notebook', 'tutorial'],\n",
       " ['how', 'solve', '90', 'nlp', 'problem'],\n",
       " ['predicting',\n",
       "  'flight',\n",
       "  'cancellations',\n",
       "  'using',\n",
       "  'weather',\n",
       "  'data',\n",
       "  'part',\n",
       "  '3'],\n",
       " ['use', 'dashdb', 'tableau'],\n",
       " ['metrics',\n",
       "  'maven',\n",
       "  'calculating',\n",
       "  'exponentially',\n",
       "  'weighted',\n",
       "  'moving',\n",
       "  'average',\n",
       "  'postgresql'],\n",
       " ['datalayer',\n",
       "  'exposed',\n",
       "  'jonas',\n",
       "  'helfer',\n",
       "  'joins',\n",
       "  'across',\n",
       "  'databases',\n",
       "  'graphql'],\n",
       " ['data', 'science', 'variable', 'selection'],\n",
       " ['d3heatmap', 'interactive', 'heat', 'map'],\n",
       " ['citizen', 'scientist', 'find', 'death', 'star', 'seti', 'data', 'set'],\n",
       " ['location', 'tracker', 'part', '2'],\n",
       " ['use', 'machine', 'learning', 'library', 'spark'],\n",
       " ['an',\n",
       "  'introduction',\n",
       "  'stock',\n",
       "  'market',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'r',\n",
       "  'part',\n",
       "  '1'],\n",
       " ['portal', 'powerups', 'deleted', 'deployments'],\n",
       " ['learn', 'tensorflow', 'deep', 'learning', 'together', 'now'],\n",
       " ['making', 'most', 'compose', 'customer', 'classcraft'],\n",
       " ['push', 'notifications', 'with', 'mongodb'],\n",
       " ['introducing', 'cloudant', 'local'],\n",
       " ['node',\n",
       "  'j',\n",
       "  'data',\n",
       "  'science',\n",
       "  'notebook',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['rethinkdb', 'compose'],\n",
       " ['got', 'phd', 'struggling', 'to', 'be', 'data', 'scientist'],\n",
       " ['deeper', 'rethinkdb', '2', '3'],\n",
       " ['simple', 'data', 'pipe', 'connectors'],\n",
       " ['10',\n",
       "  'must',\n",
       "  'attend',\n",
       "  'data',\n",
       "  'science',\n",
       "  'ml',\n",
       "  'ai',\n",
       "  'conferences',\n",
       "  '2018'],\n",
       " ['introducing',\n",
       "  'simple',\n",
       "  'search',\n",
       "  'service',\n",
       "  'faceted',\n",
       "  'search',\n",
       "  'api',\n",
       "  'made',\n",
       "  'easy'],\n",
       " ['a', 'way', 'words', 'code', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['top', 'analytics', 'tool', '2016'],\n",
       " ['introducing', 'openwhisk', 'microservices', 'made', 'easy'],\n",
       " ['is', 'postgresql', 'your', 'next', 'json', 'database'],\n",
       " ['power', 'prototyping', 'mongodb', 'node', 'red'],\n",
       " ['offline', 'first', 'offline', 'camp', 'california'],\n",
       " ['bayesian',\n",
       "  'regularization',\n",
       "  'neuralnetworks',\n",
       "  'autonomous',\n",
       "  'agents',\n",
       "  'ai'],\n",
       " ['overview', 'rstudio', 'ide', 'dsx'],\n",
       " ['data', 'science', 'expert', 'interview', 'holden', 'karau'],\n",
       " ['improving',\n",
       "  'roi',\n",
       "  'big',\n",
       "  'data',\n",
       "  'analytics',\n",
       "  'leveraging',\n",
       "  'new',\n",
       "  'sources',\n",
       "  'data'],\n",
       " ['location', 'tracker'],\n",
       " ['geospatial', 'query', 'cloudant', 'search'],\n",
       " ['compose', 'rethinkdb', '2', '3', 'driver'],\n",
       " ['foundational', 'methodology', 'data', 'science'],\n",
       " ['common', 'excel', 'tasks', 'demonstrated', 'pandas'],\n",
       " ['horizontal', 'scaling', 'arrives', 'compose', 'enterprise'],\n",
       " ['this', 'week', 'data', 'science', 'march', '28', '2017'],\n",
       " ['sensor', 'sensibility', 'hull', 'digital'],\n",
       " ['spark', '2', '1', 'job', 'monitoring', 'available', 'dsx'],\n",
       " ['data', 'science', 'real', 'time', 'streaming', 'analytics'],\n",
       " ['artificial',\n",
       "  'intelligence',\n",
       "  'ethically',\n",
       "  'speaking',\n",
       "  'inside',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'medium'],\n",
       " ['creating', 'aws', 'vpc', 'secured', 'compose', 'mongodb', 'terraform'],\n",
       " ['cloudant', 'query', 'grows', 'up', 'handle', 'ad', 'hoc', 'queries'],\n",
       " ['new', 'simple', 'data', 'pipe', 'easier', 'cloud', 'data', 'movement'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'storage',\n",
       "  'wars',\n",
       "  'the',\n",
       "  'art',\n",
       "  'genome',\n",
       "  'project'],\n",
       " ['ai', 'revolutionizes', 'industries', 'world', 'domination'],\n",
       " ['datalayer', 'conference', 'keynote', 'mitch', 'pirtle', 'capitalone'],\n",
       " ['analyze', 'open', 'data', 'set', 'using', 'panda', 'python', 'notebook'],\n",
       " ['serverless', 'autocomplete', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['charity', 'majors', 'observability', 'the', 'glorious', 'future'],\n",
       " ['a', 'beginner', 'guide', 'variational', 'methods'],\n",
       " ['load', 'xml', 'data', 'dashdb'],\n",
       " ['compose', 'tips', 'dates', 'dating', 'mongodb'],\n",
       " ['understanding',\n",
       "  'mango',\n",
       "  'view',\n",
       "  'based',\n",
       "  'indexes',\n",
       "  'v',\n",
       "  'search',\n",
       "  'based',\n",
       "  'indexes',\n",
       "  'cloudant',\n",
       "  'couchdb'],\n",
       " ['building',\n",
       "  'java',\n",
       "  'ee',\n",
       "  'webapp',\n",
       "  'ibm',\n",
       "  'bluemix',\n",
       "  'using',\n",
       "  'watson',\n",
       "  'cloudant'],\n",
       " ['this', 'week', 'data', 'science', 'february', '14', '2017'],\n",
       " ['thinky', 'rethinkdb'],\n",
       " ['the', 'potency', 'idempotent', 'rabbitmq', 'mongodb', 'upsert'],\n",
       " ['modeling', 'energy', 'usage', 'new', 'york', 'city'],\n",
       " ['compose', '2016', 'all', 'database'],\n",
       " ['data', 'wrangling', 'dplyr', 'tidyr', 'cheat', 'sheet'],\n",
       " ['connecting', 'pouchdb', 'cloudant', 'ibm', 'bluemix'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '1', 'rethinkdb'],\n",
       " ['web', 'picks', 'week', '28', 'december', '2016'],\n",
       " ['scaling', 'offline', 'first', 'envoy', 'offline', 'camp'],\n",
       " ['a', 'tour', 'redis', 'star'],\n",
       " ['how',\n",
       "  'smart',\n",
       "  'catalog',\n",
       "  'turn',\n",
       "  'big',\n",
       "  'data',\n",
       "  'flood',\n",
       "  'ocean',\n",
       "  'opportunity'],\n",
       " ['authentication',\n",
       "  'cloudant',\n",
       "  'envoy',\n",
       "  'apps',\n",
       "  'part',\n",
       "  'iii',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['using', 'bigdl', 'dsx', 'deep', 'learning', 'spark'],\n",
       " ['using', 'apply', 'sapply', 'lapply', 'r'],\n",
       " ['a',\n",
       "  'visual',\n",
       "  'explanation',\n",
       "  'back',\n",
       "  'propagation',\n",
       "  'algorithm',\n",
       "  'neural',\n",
       "  'networks'],\n",
       " ['move', 'data', 'cloud', 'dashdb', 'movetocloud', 'script'],\n",
       " ['bradley', 'holt', 'nosql', 'channel', '9'],\n",
       " ['publish', 'apps', 'use', 'r', 'analysis', 'shiny', 'dashdb'],\n",
       " ['serverless',\n",
       "  'data',\n",
       "  'flow',\n",
       "  'sequencing',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'api',\n",
       "  'ibm',\n",
       "  'cloud',\n",
       "  'functions'],\n",
       " ['web', 'picks', 'week', '23', 'january', '2017'],\n",
       " ['speed', 'sql', 'queries', 'spark', 'sql'],\n",
       " ['self', 'service', 'data', 'preparation', 'ibm', 'data', 'refinery'],\n",
       " ['bayesian', 'nonparametric', 'models', 'stats', 'bots'],\n",
       " ['3', 'scenarios', 'machine', 'learning', 'multicloud'],\n",
       " ['how', 'enable', 'redis', 'cache', 'postgresql', 'entity', 'framework', '6'],\n",
       " ['improving', 'real', 'time', 'object', 'detection', 'yolo'],\n",
       " ['deep', 'learning', 'data', 'science', 'experience'],\n",
       " ['building', 'iot', 'apps', 'cloudant', 'kiwi', 'wearables'],\n",
       " ['getting', 'started', 'graphframes', 'apache', 'spark'],\n",
       " ['spark', '1', '4', 'rstudio'],\n",
       " ['i', 'am', 'not', 'data', 'scientist', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['making', 'most', 'compose', 'customer', 'omni', 'labs'],\n",
       " ['mongo', 'metrics', 'calculating', 'mode'],\n",
       " ['notebooks', 'a', 'power', 'tool', 'data', 'scientist'],\n",
       " ['seium', 'conference', 'heartbits', 'hackathon'],\n",
       " ['offline', 'verse'],\n",
       " ['document', 'validation', 'mongodb', 'by', 'example'],\n",
       " ['introducing', 'new', 'cloudant', 'query'],\n",
       " ['querying',\n",
       "  'cloudant',\n",
       "  'database',\n",
       "  'sql',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['building', 'your', 'first', 'machine', 'learning', 'system'],\n",
       " ['data',\n",
       "  'science',\n",
       "  'expert',\n",
       "  'interview',\n",
       "  'dez',\n",
       "  'blanchfield',\n",
       "  'craig',\n",
       "  'brown',\n",
       "  'david',\n",
       "  'mathison',\n",
       "  'jennifer',\n",
       "  'shin',\n",
       "  'mike',\n",
       "  'tamir',\n",
       "  'part',\n",
       "  '2'],\n",
       " ['web', 'picks', 'week', '4', 'september', '2017'],\n",
       " ['lifelong',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'automation',\n",
       "  'help',\n",
       "  'model',\n",
       "  'get',\n",
       "  'smarter',\n",
       "  'time'],\n",
       " ['apple',\n",
       "  'ibm',\n",
       "  'add',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'partnership',\n",
       "  'watson',\n",
       "  'core',\n",
       "  'ml',\n",
       "  'coupling'],\n",
       " ['redis', 'pubsub', 'node', 'socket', 'io'],\n",
       " ['xml2', '1', '0', '0'],\n",
       " ['building', 'cloudant', 'cluster', 'raspberry', 'pis'],\n",
       " ['open', 'sourcing', '223gb', 'driving', 'data', 'udacity', 'inc'],\n",
       " ['etcd', '2', '3', 'new', 'apis', 'new', 'possibility'],\n",
       " ['the', 'machine', 'learning', 'database'],\n",
       " ['replicate', 'sample', 'database'],\n",
       " ['ibm', 'new', 'builders', 'podcast'],\n",
       " ['december', '16', 'rstudio', 'tips', 'tricks'],\n",
       " ['introducing',\n",
       "  'spark',\n",
       "  'cloudant',\n",
       "  'open',\n",
       "  'source',\n",
       "  'spark',\n",
       "  'connector',\n",
       "  'cloudant',\n",
       "  'data'],\n",
       " ['redis', 'configuration', 'controls'],\n",
       " ['developing',\n",
       "  'ibm',\n",
       "  'streams',\n",
       "  'application',\n",
       "  'python',\n",
       "  'api',\n",
       "  'version',\n",
       "  '1',\n",
       "  '6'],\n",
       " ['sentiment', 'analysis', 'reddit', 'amas'],\n",
       " ['sector', 'correlations', 'shiny', 'app'],\n",
       " ['this', 'week', 'data', 'science', 'september', '06', '2016'],\n",
       " ['learning', 'statistics', 'youtube'],\n",
       " ['configuring', 'compose', 'enterprise', 'google', 'cloud', 'platform'],\n",
       " ['simple',\n",
       "  'data',\n",
       "  'visualization',\n",
       "  'apache',\n",
       "  'couchdb',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['statistical', 'bias', 'types', 'explained', 'example'],\n",
       " ['how', 'analyze', 'pipe', 'run', 'bunyan'],\n",
       " ['do', 'more', 'compose', 'postgresql', 'using', 'zapier'],\n",
       " ['integrate', 'dashdb', 'excel'],\n",
       " ['work', 'data', 'connections', 'dsx'],\n",
       " ['deep', 'learning', 'trend', 'example'],\n",
       " ['how', 'talk', 'raw', 'redis'],\n",
       " ['using', 'lucene', 'search', 'within', 'couchdb'],\n",
       " ['analyzing', 'pet', 'name', 'trends', 'postgresql', 'crosstabview'],\n",
       " ['customer', 'drone', 'deploy', 'conquers', 'data', 'layer'],\n",
       " ['twelve', 'way', 'color', 'map', 'africa', 'using', 'brunel'],\n",
       " ['apache',\n",
       "  'spark',\n",
       "  '2',\n",
       "  '0',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'under',\n",
       "  'hood',\n",
       "  'over',\n",
       "  'rainbow'],\n",
       " ['metrics',\n",
       "  'maven',\n",
       "  'crosstab',\n",
       "  'revisited',\n",
       "  'pivoting',\n",
       "  'wisely',\n",
       "  'postgresql'],\n",
       " ['using', 'cloudant', 'enhance', 'uploads', 'ibm', 'graph'],\n",
       " ['compose', 'mysql', 'a', 'developer', 'view'],\n",
       " ['this', 'week', 'data', 'science', 'january', '31', '2017'],\n",
       " ['writing', 'data', 'directly', 'cloudant', 'slack'],\n",
       " ['elasticsearch', 'tools', 'compose'],\n",
       " ['a',\n",
       "  'guide',\n",
       "  'receptive',\n",
       "  'field',\n",
       "  'arithmetic',\n",
       "  'convolutional',\n",
       "  'neural',\n",
       "  'networks'],\n",
       " ['understand', 'replication', 'work'],\n",
       " ['open', 'data', 'day', 'economic', 'justice', 'civic', 'engagement'],\n",
       " ['10', 'common', 'misconceptions', 'couchdb'],\n",
       " ['awesome', 'deep', 'learning', 'paper'],\n",
       " ['making', 'smart', 'business', 'chatbot', 'part', '3'],\n",
       " ['dimensionality', 'reduction', 'algorithms'],\n",
       " ['join', 'enrich', 'data', 'multiple', 'source'],\n",
       " ['brunel', 'in', 'jupyter'],\n",
       " ['introducing', 'compose', 'big', 'bits'],\n",
       " ['accessing', 'relational', 'databases', 'using', 'go'],\n",
       " ['accelerate', 'your', 'workflow', 'dsx'],\n",
       " ['backpropagation',\n",
       "  'how',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'learn',\n",
       "  'complex',\n",
       "  'behaviors'],\n",
       " ['this', 'week', 'data', 'science', 'august', '30', '2016'],\n",
       " ['mysql', 'json', 'generated', 'columns', 'indexing'],\n",
       " ['moving', 'medium'],\n",
       " ['datalayer', 'conference', 'ambry', 'linkedin'],\n",
       " ['glynnbird', 'couchimport'],\n",
       " ['perform', 'group', 'facet', 'and', 'geo', 'searches', 'cloudant'],\n",
       " ['time',\n",
       "  'series',\n",
       "  'prediction',\n",
       "  'using',\n",
       "  'recurrent',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'lstms'],\n",
       " ['probabilistic',\n",
       "  'graphical',\n",
       "  'models',\n",
       "  'tutorial',\n",
       "  'part',\n",
       "  '2',\n",
       "  'stats',\n",
       "  'bots'],\n",
       " ['on', 'demand', 'backup', 'compose', 'api', 'node', 'j'],\n",
       " ['what', 'machine', 'learning'],\n",
       " ['some', 'random', 'weekend', 'reading'],\n",
       " ['neurally', 'embedded', 'emojis'],\n",
       " ['leverage',\n",
       "  'python',\n",
       "  'scikit',\n",
       "  'text',\n",
       "  'classification',\n",
       "  'behavioral',\n",
       "  'profiling'],\n",
       " ['authentication',\n",
       "  'cloudant',\n",
       "  'envoy',\n",
       "  'apps',\n",
       "  'part',\n",
       "  'ii',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['use', 'dashdb', 'pyspark', 'pandas'],\n",
       " ['using',\n",
       "  'shell',\n",
       "  'script',\n",
       "  'control',\n",
       "  'data',\n",
       "  'flow',\n",
       "  'created',\n",
       "  'watson',\n",
       "  'application'],\n",
       " ['couchdb', 'document', 'copy', 'transform', 'service'],\n",
       " ['getting', 'started', 'elasticsearch', 'node', 'j', 'part', '3'],\n",
       " ['mastering', 'postgresql', 'tool', 'filters', 'foreign', 'data', 'wrappers'],\n",
       " ['manage', 'object', 'storage', 'dsx'],\n",
       " ['mycheatsheets', 'com'],\n",
       " ['map', 'your', 'cloud', 'data'],\n",
       " ['introducing', 'ibm', 'graph'],\n",
       " ['enhanced', 'cloudant', 'search', 'watson', 'alchemy'],\n",
       " ['now', 'available', 'ibm', 'bluemix'],\n",
       " ['introduction', 'market', 'basket', 'analysis', 'python'],\n",
       " ['brunel', 'imitation', 'sincere', 'form', 'flattery'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'porting',\n",
       "  'zendesk',\n",
       "  'existing',\n",
       "  'app',\n",
       "  'graphql'],\n",
       " ['deploying', 'logshare', 'compose', 'bluemix'],\n",
       " ['a', 'deep', 'dive', 'offline', 'first', 'pouchdb', 'ibm', 'cloudant'],\n",
       " ['open',\n",
       "  'source',\n",
       "  'fun',\n",
       "  'learning',\n",
       "  'kudos',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['creating', 'notebooks', 'ibm', 'data', 'science', 'experience'],\n",
       " ['challenges', 'deep', 'learning'],\n",
       " ['generalization', 'deep', 'learning'],\n",
       " ['authenticating', 'node', 'red', 'jsonwebtoken', 'part', '1'],\n",
       " ['get', 'started', 'streams', 'designer', 'following', 'roadmap'],\n",
       " ['geofile', 'elasticsearch', 'geo', 'queries'],\n",
       " ['metrics',\n",
       "  'maven',\n",
       "  'creating',\n",
       "  'pivot',\n",
       "  'tables',\n",
       "  'postgresql',\n",
       "  'using',\n",
       "  'crosstab'],\n",
       " ['load', 'data', 'cloud', 'dashdb'],\n",
       " ['introducing',\n",
       "  'meteor',\n",
       "  'toys',\n",
       "  '3',\n",
       "  'because',\n",
       "  'toys',\n",
       "  'make',\n",
       "  'life',\n",
       "  'better'],\n",
       " ['this', 'week', 'data', 'science', 'october', '25', '2016'],\n",
       " ['use', 'secondary', 'index', 'cloudant'],\n",
       " ['fighting',\n",
       "  'gerrymandering',\n",
       "  'using',\n",
       "  'data',\n",
       "  'science',\n",
       "  'draw',\n",
       "  'fairer',\n",
       "  'congressional',\n",
       "  'district'],\n",
       " ['announcing', 'dsx', 'environments', 'beta'],\n",
       " ['this', 'week', 'data', 'science', 'april', '25', '2017'],\n",
       " ['ibm',\n",
       "  'data',\n",
       "  'science',\n",
       "  'experience',\n",
       "  'white',\n",
       "  'paper',\n",
       "  'sparkr',\n",
       "  'transforming',\n",
       "  'r',\n",
       "  'tool',\n",
       "  'big',\n",
       "  'data',\n",
       "  'analytics'],\n",
       " ['collect', 'your', 'own', 'fitbit', 'data', 'python'],\n",
       " ['do', 'i', 'need', 'learn', 'r'],\n",
       " ['how', 'ibm', 'build', 'effective', 'data', 'science', 'team'],\n",
       " ['sparklyr', 'r', 'interface', 'apache', 'spark'],\n",
       " ['build', 'search', 'index', 'cloudant'],\n",
       " ['run', 'shiny', 'applications', 'rstudio', 'dsx'],\n",
       " ['deep', 'learning', 'structure', 'innate', 'priors'],\n",
       " ['lorna', 'jane', 'mitchell', 'surviving', 'failure', 'rabbitmq'],\n",
       " ['meteor', '1', '4', 'mongodb', 'compose', 'ready', 'oplog'],\n",
       " ['optimizing', 'marketing', 'campaign', 'moving', 'prediction', 'action'],\n",
       " ['intro', 'cloudant', 'query', 'declarative', 'query', 'api', 'json'],\n",
       " ['location', 'tracker', 'offline', 'first', 'design', 'swift'],\n",
       " ['dsx', 'hybrid', 'mode'],\n",
       " ['migration',\n",
       "  'ibm',\n",
       "  'bluemix',\n",
       "  'data',\n",
       "  'connect',\n",
       "  'api',\n",
       "  'activity',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'api',\n",
       "  'data',\n",
       "  'flow'],\n",
       " ['this', 'week', 'data', 'science', 'october', '18', '2016'],\n",
       " ['graph', 'based', 'machine', 'learning'],\n",
       " ['go', 'serverless', 'apex', 'compose', 'mongodb'],\n",
       " ['clustering', 'a', 'guide', 'perplexed'],\n",
       " ['visualising', 'data', 'node', 'j', 'way'],\n",
       " ['snowzilla'],\n",
       " ['upload', 'data', 'create', 'data', 'frames', 'jupyter', 'notebooks'],\n",
       " ['making', 'compose', 'customer', 'fathom'],\n",
       " ['integrate',\n",
       "  'user',\n",
       "  'management',\n",
       "  'cloudant',\n",
       "  'query',\n",
       "  'node',\n",
       "  'j',\n",
       "  'cloudant',\n",
       "  'application'],\n",
       " ['have', 'the', 'talk', 'chatbot', 'graph', 'data', 'structure'],\n",
       " ['working', 'notebook', 'dsx'],\n",
       " ['introducing', 'cloudant', 'sync', 'open', 'source', 'libraries', 'mobile'],\n",
       " ['apache', 'systemml'],\n",
       " ['ggplot2', '2', '2', '0', 'coming', 'soon'],\n",
       " ['transporter', '0', '3', '0', 'released', 'transporter', 'streamlined'],\n",
       " ['use', 'dashdb', 'watson', 'analytics'],\n",
       " ['data', 'structures', 'related', 'machine', 'learning', 'algorithms'],\n",
       " ['analyze',\n",
       "  'market',\n",
       "  'trends',\n",
       "  'twitter',\n",
       "  'using',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'python',\n",
       "  'dashdb'],\n",
       " ['a', 'classification', 'problem'],\n",
       " ['what', 'text', 'analytics'],\n",
       " ['an', 'interview', 'pythonista', 'katharine', 'jarmul'],\n",
       " ['continuous', 'learning', 'watson'],\n",
       " ['load', 'geospatial', 'data', 'dashdb', 'analyze', 'esri', 'arcgis'],\n",
       " ['introduction', 'document', 'conflict', 'part', 'one'],\n",
       " ['why', 'replication', 'awesome'],\n",
       " ['aggregations', 'mongodb', 'example'],\n",
       " ['apache', 'spark', '2', '0', 'impressive', 'improvements', 'spark', 'sql'],\n",
       " ['introducing', 'ibm', 'watson', 'studio'],\n",
       " ['building', 'better', 'database', 'bridge', 'new', 'compose', 'transporter'],\n",
       " ['let', 'build', 'server', 'cf', 'push', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['authentication',\n",
       "  'cloudant',\n",
       "  'envoy',\n",
       "  'apps',\n",
       "  'part',\n",
       "  'i',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '4', 'cloudant'],\n",
       " ['run', 'dsx', 'notebooks', 'amazon', 'emr'],\n",
       " ['how', 'compose', 'helping', 'educational', 'organizations', 'innovate'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'rethinking',\n",
       "  'indexing',\n",
       "  'data',\n",
       "  'stores',\n",
       "  'replex'],\n",
       " ['using',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'parallel',\n",
       "  'processing',\n",
       "  'framework',\n",
       "  'accessing',\n",
       "  'rest',\n",
       "  'based',\n",
       "  'data',\n",
       "  'service'],\n",
       " ['predicting', 'the', '2016', 'us', 'presidential', 'election'],\n",
       " ['read', 'write', 'data', 'to', 'from', 'amazon', 's3', 'buckets', 'rstudio'],\n",
       " ['the', 'well', 'connected', 'rabbit'],\n",
       " ['metrics', 'maven', 'meet', 'middle', 'median', 'postgresql'],\n",
       " ['show', 'twitter', 'trend', 'spark', 'streaming', 'ibm', 'watson'],\n",
       " ['persistent', 'change', 'spark', 'config', 'dsx'],\n",
       " ['window', 'frames', 'postgresql'],\n",
       " ['this', 'week', 'data', 'science', 'november', '29', '2016'],\n",
       " ['cloudant', 'learning', 'center'],\n",
       " ['let', 'encrypt', 'tls', 'certificates'],\n",
       " ['using', 'github', 'project', 'control', 'dsx'],\n",
       " ['using', 'rethinkdb', '2', '3', 'user', 'authentication'],\n",
       " ['0',\n",
       "  'life',\n",
       "  'changing',\n",
       "  'app',\n",
       "  'new',\n",
       "  'apache',\n",
       "  'systemml',\n",
       "  'api',\n",
       "  'spark',\n",
       "  'shell'],\n",
       " ['adoption', 'machine', 'learning', 'software', 'failure', 'prediction'],\n",
       " ['join', 'u', 'offline', 'camp'],\n",
       " ['custom',\n",
       "  'cloudant',\n",
       "  'replication',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['using', 'machine', 'learning', 'predict', 'value', 'homes', 'on', 'airbnb'],\n",
       " ['using', 'maker', 'palette', 'ibm', 'data', 'science', 'experience'],\n",
       " ['ibm', 'data', 'catalog', 'overview'],\n",
       " ['postgresql', 'backups', 'everything', 'need', 'know'],\n",
       " ['geospatial', 'nearest', 'neighbor', 'query'],\n",
       " ['cache', 'table', 'apache', 'spark', 'sql'],\n",
       " ['navigating',\n",
       "  'sxsw',\n",
       "  'via',\n",
       "  'cognitive',\n",
       "  'chatbot',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['brunel', '2', '0', 'preview'],\n",
       " ['web',\n",
       "  'application',\n",
       "  'state',\n",
       "  'la',\n",
       "  'dogfight',\n",
       "  '1983',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['create', 'tables', 'dashdb'],\n",
       " ['turn', 'small', 'data', 'into', 'smart', 'data', 'part', '3'],\n",
       " ['migrating', 'python', '3', 'pleasure'],\n",
       " ['ibm', 'data', 'catalog', 'generally', 'available'],\n",
       " ['data',\n",
       "  'science',\n",
       "  'experience',\n",
       "  'demo',\n",
       "  'modeling',\n",
       "  'energy',\n",
       "  'usage',\n",
       "  'nyc'],\n",
       " ['why', 'relational', 'databases', 'r'],\n",
       " ['the', 'new', 'builders', 'podcast', 'ep', '3', 'collaboration'],\n",
       " ['making', 'most', 'compose', 'customer', 'dronedeploy'],\n",
       " ['learn', 'read', 'write', 'ops', 'couchdb', '2', '0', 'work', 'cluster'],\n",
       " ['a',\n",
       "  'depth',\n",
       "  'first',\n",
       "  'look',\n",
       "  'watson',\n",
       "  'conversation',\n",
       "  'gremlin',\n",
       "  'janusgraph'],\n",
       " ['customer', 'icars', 'conquers', 'data', 'layer'],\n",
       " ['build', 'simple', 'data', 'portal', 'python', 'ibm', 'object', 'storage'],\n",
       " ['building', 'ohlc', 'data', 'postgresql'],\n",
       " ['ibm', 'watson', 'machine', 'learning', 'get', 'started'],\n",
       " ['database',\n",
       "  'change',\n",
       "  'search',\n",
       "  'index',\n",
       "  'go',\n",
       "  'together',\n",
       "  'like',\n",
       "  'wine',\n",
       "  'cheese',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '7', 'redis'],\n",
       " ['this', 'week', 'data', 'science', 'january', '24', '2017'],\n",
       " ['multiplying', 'microservices'],\n",
       " ['introducing', 'cloudant', 'query'],\n",
       " ['load', 'db2', 'warehouse', 'cloud', 'data', 'apache', 'spark', 'dsx'],\n",
       " ['declarative', 'machine', 'learning'],\n",
       " ['how',\n",
       "  'marketing',\n",
       "  'technology',\n",
       "  'companies',\n",
       "  'use',\n",
       "  'compose',\n",
       "  'conquer',\n",
       "  'their',\n",
       "  'data',\n",
       "  'layer'],\n",
       " ['what', 'new', 'data', 'refinery'],\n",
       " ['get', 'line', 'an', 'intro', 'queues', 'pubsub'],\n",
       " ['this', 'week', 'data', 'science', 'april', '11', '2017'],\n",
       " ['mysql', 'json'],\n",
       " ['on', 'passage', 'hb2', 'north', 'carolina'],\n",
       " ['change', 'database', 'permissions', 'cloudant'],\n",
       " ['data', 'privacy', 'governance', 'update'],\n",
       " ['baby',\n",
       "  'first',\n",
       "  'ibm',\n",
       "  'graph',\n",
       "  'app',\n",
       "  'using',\n",
       "  'node',\n",
       "  'j',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['database', 'design', 'load', 'query', 'r'],\n",
       " ['make', 'machine', 'learning', 'reality', 'enterprise'],\n",
       " ['bluemix',\n",
       "  'object',\n",
       "  'storage',\n",
       "  'enhanced',\n",
       "  'update',\n",
       "  'precipitation',\n",
       "  'analysis',\n",
       "  'sample',\n",
       "  'notebook'],\n",
       " ['getting', 'started', 'compose', 'bluemix'],\n",
       " ['10',\n",
       "  'things',\n",
       "  'i',\n",
       "  'hate',\n",
       "  'about',\n",
       "  'your',\n",
       "  'api',\n",
       "  'amanda',\n",
       "  'folson',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['hacking',\n",
       "  'v',\n",
       "  'prototyping',\n",
       "  'v',\n",
       "  'production',\n",
       "  'code',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['web', 'picks', 'dataminingapps'],\n",
       " ['this', 'week', 'data', 'science', 'september', '13', '2016'],\n",
       " ['i',\n",
       "  'rather',\n",
       "  'predict',\n",
       "  'basketball',\n",
       "  'games',\n",
       "  'than',\n",
       "  'elections',\n",
       "  'elastic',\n",
       "  'nba',\n",
       "  'rankings'],\n",
       " ['what', 'spark'],\n",
       " ['use',\n",
       "  'ibm',\n",
       "  'data',\n",
       "  'science',\n",
       "  'experience',\n",
       "  'detect',\n",
       "  'time',\n",
       "  'series',\n",
       "  'anomaly'],\n",
       " ['introduction', 'neural', 'networks', 'advantages', 'applications'],\n",
       " ['compose', 'data', 'browser', 'come', 'elasticsearch'],\n",
       " ['geofile',\n",
       "  'converting',\n",
       "  'importing',\n",
       "  'shapefiles',\n",
       "  'compose',\n",
       "  'postgresql',\n",
       "  'mongodb'],\n",
       " ['what', 'hadoop'],\n",
       " ['connect', 'apps', 'dashdb'],\n",
       " ['what', 'new', 'streaming', 'analytics', 'service', 'bluemix'],\n",
       " ['using', 'cloudant', 'node', 'j'],\n",
       " ['use', 'advanced', 'technique', 'secondary', 'index', 'cloudant'],\n",
       " ['intelligent', 'application', 'apache', 'spark'],\n",
       " ['publish', 'notebook', 'github', 'dsx'],\n",
       " ['gradient', 'boosting', 'explained'],\n",
       " ['compose', 'postgresql', 'new', 'performance', 'extensions', 'view'],\n",
       " ['markdown', 'jupyter', 'notebook', 'cheatsheet'],\n",
       " ['create',\n",
       "  'business',\n",
       "  'intelligence',\n",
       "  'analytics',\n",
       "  'service',\n",
       "  'ruby',\n",
       "  'dashdb',\n",
       "  'service'],\n",
       " ['drowning',\n",
       "  'data',\n",
       "  'source',\n",
       "  'how',\n",
       "  'data',\n",
       "  'cataloging',\n",
       "  'could',\n",
       "  'fix',\n",
       "  'findability',\n",
       "  'problem'],\n",
       " ['optimization', 'deep', 'learning', 'highlights', '2017'],\n",
       " ['building',\n",
       "  'mobile',\n",
       "  'apps',\n",
       "  'at',\n",
       "  'the',\n",
       "  'geospatial',\n",
       "  'edge',\n",
       "  'for',\n",
       "  'shipping',\n",
       "  'logistics',\n",
       "  'transportation'],\n",
       " ['using',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'with',\n",
       "  'keras',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'customer',\n",
       "  'churn'],\n",
       " ['convert', 'ibm', 'puredata', 'analytics', 'dashdb'],\n",
       " ['compose', 'enterprise', 'come', 'bluemix'],\n",
       " ['a', 'moving', 'average', 'trading', 'strategy'],\n",
       " ['use', 'spark', 'r', 'load', 'analyze', 'data'],\n",
       " ['get', 'started', 'with', 'couchdb', 'using', 'php', 'guzzle'],\n",
       " ['getting', 'started', 'elasticsearch', 'node', 'j', 'part', '4'],\n",
       " ['amy', 'unruh', 'scaling', 'out', 'sql', 'databases', 'spanner'],\n",
       " ['hoodie', 'app', 'tracker', 'deployable', 'ibm', 'bluemix'],\n",
       " ['this', 'week', 'data', 'science', 'may', '23', '2017'],\n",
       " ['web', 'picks', 'dataminingapps'],\n",
       " ['this', 'week', 'data', 'science', 'october', '11', '2016'],\n",
       " ['python',\n",
       "  'for',\n",
       "  'loops',\n",
       "  'explained',\n",
       "  'python',\n",
       "  'data',\n",
       "  'science',\n",
       "  'basics',\n",
       "  '5'],\n",
       " ['top', '10', 'machine', 'learning', 'algorithms', 'beginners'],\n",
       " ['how',\n",
       "  'i',\n",
       "  'used',\n",
       "  'serverless',\n",
       "  'infrastructure',\n",
       "  'build',\n",
       "  'large',\n",
       "  'scale',\n",
       "  'petition',\n",
       "  'system',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['backups', 'etcd', 'etcdtool'],\n",
       " ['bach', 'the', 'compose', 'api', 'command', 'line'],\n",
       " ['let', 'data', 'dictate', 'visualization'],\n",
       " ['the',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'ai',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'deep',\n",
       "  'learning'],\n",
       " ['defensive',\n",
       "  'ibm',\n",
       "  'object',\n",
       "  'storage',\n",
       "  'containers',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['this', 'week', 'data', 'science', 'august', '02', '2016'],\n",
       " ['connecting', 'compose', 'mongodb', 'java', 'ssl'],\n",
       " ['this', 'week', 'data', 'science', 'december', '27', '2016'],\n",
       " ['connection', 'pooling', 'mongodb'],\n",
       " ['conquer', 'email', 'postal', 'compose'],\n",
       " ['use', 'dashdb', 'ibm', 'embeddable', 'reporting', 'service'],\n",
       " ['data', 'science', 'cloud'],\n",
       " ['introduction', 'graph', 'databases'],\n",
       " ['this', 'week', 'data', 'science', 'may', '30', '2017'],\n",
       " ['put', 'human', 'face', 'machine', 'learning', 'wml', 'dsx'],\n",
       " ['use', 'bluemix', 'dashdb', 'r', 'solve', 'kaggle', 'competition'],\n",
       " ['search', 'indexes'],\n",
       " ['coding', 'eventual', 'consistency'],\n",
       " ['the',\n",
       "  'art',\n",
       "  'side',\n",
       "  'effects',\n",
       "  'curing',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'streaming',\n",
       "  'amnesia',\n",
       "  'part',\n",
       "  '1',\n",
       "  '2'],\n",
       " ['simple',\n",
       "  'csv',\n",
       "  'import',\n",
       "  'for',\n",
       "  'couchdb',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['shaping', 'data', 'ibm', 'data', 'refinery'],\n",
       " ['cloud', 'data', 'warehouse', 'made', 'easy'],\n",
       " ['better', 'infrastructure', 'maintenance', 'offline', 'mobile', 'map'],\n",
       " ['debugging', 'lua', 'redis'],\n",
       " ['learn', 'data', 'science', 'world', 'watson'],\n",
       " ['share', 'pixiedust', 'magic', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['scale', 'web', 'app', 'microservices', 'ibm', 'message', 'hub'],\n",
       " ['data', 'science', 'platform', 'rise', 'ibm', 'leading', 'way'],\n",
       " ['new', 'shiny', 'cheat', 'sheet', 'video', 'tutorial'],\n",
       " ['a', 'guest', 'video', 'post'],\n",
       " ['a', 'how', 'migrating', 'etcd', '2', 'etcd', '3'],\n",
       " ['10', 'tip', 'using', 'jupyter', 'notebook'],\n",
       " ['create', 'project', 'add', 'data', 'using', 'ibm', 'data', 'refinery'],\n",
       " ['what', 'you', 'need', 'know', 'extend', 'nifi'],\n",
       " ['oscon', 'europe', 'talk', 'review'],\n",
       " ['the', 'two', 'phases', 'gradient', 'descent', 'deep', 'learning'],\n",
       " ['move', 'matplotlib', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['dplyr', '0', '5', '0'],\n",
       " ['a', 'deep', 'dive', 'offline', 'first', 'pouchdb', 'ibm', 'cloudant'],\n",
       " ['embed', 'rich', 'report', 'application'],\n",
       " ['compose', 'postgresql', 'power', '9', '6'],\n",
       " ['use', 'curl', 'set', 'replication'],\n",
       " ['convert', 'data', 'oracle', 'dashdb'],\n",
       " ['sentiment', 'analysis', 'reddit', 'amas', 'using', 'dashdb', 'r'],\n",
       " ['datalayer',\n",
       "  'exposed',\n",
       "  'ross',\n",
       "  'kukulinski',\n",
       "  'the',\n",
       "  'state',\n",
       "  'of',\n",
       "  'state',\n",
       "  'in',\n",
       "  'containers'],\n",
       " ['getting', 'started', 'python'],\n",
       " ['ibm', 'analytics', 'esri', 'partner', 'developer', 'summit'],\n",
       " ['data', 'visualization', 'ggplot2', 'cheat', 'sheet'],\n",
       " ['zero', 'kubernetes', 'ibm', 'bluemix', 'container', 'service'],\n",
       " ['syncing',\n",
       "  'car',\n",
       "  'telemetry',\n",
       "  'data',\n",
       "  'real',\n",
       "  'time',\n",
       "  'ford',\n",
       "  'openxc',\n",
       "  'api',\n",
       "  'cloudant',\n",
       "  'traffic',\n",
       "  'tamer',\n",
       "  'app'],\n",
       " ['trust', 'data', 'science'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'scylla',\n",
       "  'high',\n",
       "  'performance',\n",
       "  'cassandra',\n",
       "  'successor'],\n",
       " ['this', 'week', 'data', 'science', 'december', '13', '2016'],\n",
       " ['5', 'minute', 'signup', 'forms', 'node', 'red', 'compose'],\n",
       " ['datalayer', 'conference', 'bootstrapping', 'startup', 'using', 'compose'],\n",
       " ['offline', 'first', 'ios', 'apps', 'swift', 'cloudant', 'sync', 'part', '3'],\n",
       " ['which', 'one', 'choose', 'your', 'problem'],\n",
       " ['rethinkdb',\n",
       "  'life',\n",
       "  'redis',\n",
       "  'postgresql',\n",
       "  'future',\n",
       "  'fosdem',\n",
       "  'rust',\n",
       "  'wuzz'],\n",
       " ['build', 'naive', 'bayes', 'model', 'wml', 'dsx'],\n",
       " ['cloudant',\n",
       "  'node',\n",
       "  'j',\n",
       "  'made',\n",
       "  'simple',\n",
       "  'silverlining',\n",
       "  'library',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['let', 'fun', 'nfl', 'data'],\n",
       " ['mongo', 'metrics', 'calculating', 'mean'],\n",
       " ['this', 'week', 'data', 'science', 'april', '4', '2017'],\n",
       " ['load', 'cloudant', 'data', 'apache', 'spark', 'using', 'scala', 'notebook'],\n",
       " ['set', 'up', 'pre', 'authenticated', 'curl'],\n",
       " ['data', 'connect', 'cloud', 'data', 'prep', 'movement'],\n",
       " ['rstudio', 'ide', 'cheat', 'sheet'],\n",
       " ['dt', 'an', 'r', 'interface', 'datatables', 'library'],\n",
       " ['how', 'watch', 'wait', 'compose', 'bach', 'api'],\n",
       " ['the',\n",
       "  'distribution',\n",
       "  'key',\n",
       "  'statistical',\n",
       "  'concept',\n",
       "  'discovered',\n",
       "  'beer',\n",
       "  'brewery'],\n",
       " ['you', 'could', 'looking', 'wrong'],\n",
       " ['build', 'ios', '8', 'app', 'bluemix', 'mobilefirst', 'platform', 'ios'],\n",
       " ['how', 'data', 'scientist', 'collaborate', 'build', 'better', 'business'],\n",
       " ['making', 'most', 'compose', 'case', 'study', 'differential'],\n",
       " ['getting', 'started', 'elasticsearch', 'node', 'j', 'part', '1'],\n",
       " ['offline', 'first', 'what', 'name', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['moving',\n",
       "  'data',\n",
       "  'documentdb',\n",
       "  'cloudant',\n",
       "  'couchdb',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['getting', 'started', 'elasticsearch', 'node', 'j', 'part', '5'],\n",
       " ['the',\n",
       "  'new',\n",
       "  'builders',\n",
       "  'ep',\n",
       "  '13',\n",
       "  'all',\n",
       "  'data',\n",
       "  'that',\n",
       "  'fit',\n",
       "  'analyze'],\n",
       " ['offline',\n",
       "  'radioactively',\n",
       "  'clean',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['use', 'primary', 'index'],\n",
       " ['data', 'driven', 'shopper', 'insights'],\n",
       " ['why',\n",
       "  'it',\n",
       "  'consulting',\n",
       "  'developer',\n",
       "  'services',\n",
       "  'companies',\n",
       "  'love',\n",
       "  'compose'],\n",
       " ['transporter', 'mongodb', 'synchronization'],\n",
       " ['geofile',\n",
       "  'how',\n",
       "  'transform',\n",
       "  'openstreetmap',\n",
       "  'data',\n",
       "  'geojson',\n",
       "  'using',\n",
       "  'gdal'],\n",
       " ['tibble', '1', '1'],\n",
       " ['the', 'million', 'dollar', 'question', 'where', 'data'],\n",
       " ['this', 'week', 'data', 'science', 'december', '06', '2016'],\n",
       " ['tidyverse', 'practice', 'mapping', 'large', 'european', 'city'],\n",
       " ['building', 'business', 'combine', 'human', 'expert', 'data', 'science'],\n",
       " ['offline', 'first', 'ios', 'apps', 'swift', 'cloudant', 'sync', 'part', '2'],\n",
       " ['tidyr', '0', '6', '0'],\n",
       " ['making', 'most', 'compose', 'customer', 'flying', 'donut'],\n",
       " ['making', 'most', 'compose', 'customer', 'icanmakeitbetter'],\n",
       " ['using', 'nosql', 'dbaas', 'launch', 'life', 'science', 'software'],\n",
       " ['apache', 'spark', 'analytics'],\n",
       " ['upload',\n",
       "  'files',\n",
       "  'ibm',\n",
       "  'data',\n",
       "  'science',\n",
       "  'experience',\n",
       "  'using',\n",
       "  'command',\n",
       "  'line'],\n",
       " ['ny', 'motor', 'vehicle', 'accident', 'analysis'],\n",
       " ['load', 'dashdb', 'data', 'apache', 'spark'],\n",
       " ['integration', 'testing', 'against', 'real', 'databases'],\n",
       " ['take', 'dip', 'postgresql', 'arrays'],\n",
       " ['kibana', 'compose', 'elasticsearch'],\n",
       " ['random',\n",
       "  'forest',\n",
       "  'interpretation',\n",
       "  'conditional',\n",
       "  'feature',\n",
       "  'contribution'],\n",
       " ['access', 'ibm', 'analytics', 'apache', 'spark', 'rstudio'],\n",
       " ['how', 'hyver', 'us', 'scylladb', 'api', 'key', 'management'],\n",
       " ['manage', 'your', 'business', 'compose', 'odoo', 'bluemix'],\n",
       " ['choosing', 'cloudant', 'library', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['the', '3', 'cs', 'big', 'data'],\n",
       " ['how', 'move', 'data', 'transporter', 'disk', 'database'],\n",
       " ['web', 'picks', 'december', '2017'],\n",
       " ['recommendation', 'system', 'algorithms', 'stats', 'bots'],\n",
       " ['a', 'first', 'peek', 'next', 'mongodb'],\n",
       " ['simple', 'linear', 'regression', 'do', 'it', 'the', 'bayesian', 'way'],\n",
       " ['back', 'basic', 'jupyter', 'notebook'],\n",
       " ['trigger',\n",
       "  'periodic',\n",
       "  'openwhisk',\n",
       "  'actions',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['block', 'chain', 'technology', 'smart', 'contract', 'ethereum'],\n",
       " ['accessing', 'ibm', 'graph', 'java', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['making', 'most', 'compose', 'enterprise', 'customer', 'readme', 'io'],\n",
       " ['offline', 'first', 'mobile', 'apps', 'ibm', 'cloudant'],\n",
       " ['three', 'reason', 'machine', 'learning', 'model', 'go', 'sync'],\n",
       " ['pixiedust',\n",
       "  'get',\n",
       "  'first',\n",
       "  'community',\n",
       "  'driven',\n",
       "  'feature',\n",
       "  '1',\n",
       "  '0',\n",
       "  '4'],\n",
       " ['can', 'a', 'i', 'be', 'taught', 'explain', 'itself'],\n",
       " ['connecting', 'rethinkdb', 'elixir'],\n",
       " ['define', 'index', 'query'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '3', 'postgresql'],\n",
       " ['htmlwidgets', 'javascript', 'data', 'visualization', 'r'],\n",
       " ['redis', 'data', 'browser', 'now', 'available', 'compose', 'dashboard'],\n",
       " ['top',\n",
       "  '6',\n",
       "  'questions',\n",
       "  'webinar',\n",
       "  'top',\n",
       "  '6',\n",
       "  'questions',\n",
       "  'sql',\n",
       "  'nosql',\n",
       "  'migrations'],\n",
       " ['have',\n",
       "  'the',\n",
       "  'talk',\n",
       "  'chatbot',\n",
       "  'graph',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['analyze', 'db2', 'warehouse', 'cloud', 'data', 'rstudio', 'dsx'],\n",
       " ['importing', 'redis', 'data', 'compose', 'redis'],\n",
       " ['data',\n",
       "  'warehousing',\n",
       "  'features',\n",
       "  'improvements',\n",
       "  'updates',\n",
       "  'introducing',\n",
       "  'new',\n",
       "  'dashdb'],\n",
       " ['create', 'database', 'add', 'documents', 'database'],\n",
       " ['taking', 'look', 'robomongo', 'studio', '3t', 'compose', 'mongodb'],\n",
       " ['this', 'week', 'data', 'science', 'january', '17', '2017'],\n",
       " ['hyperparameter', 'optimization', 'sven', 'hafeneger'],\n",
       " ['check', 'status', 'replication', 'job'],\n",
       " ['working', 'db2', 'warehouse', 'cloud', 'data', 'science', 'experience'],\n",
       " ['ux', 'improvements', 'cloudant', 'data', 'replication'],\n",
       " ['one', 'year', 'data', 'scientist', 'stack', 'overflow'],\n",
       " ['load', 'json', 'cloudant', 'database', 'dashdb'],\n",
       " ['metrics', 'maven', 'calculating', 'weighted', 'average', 'postgresql'],\n",
       " ['tracking', 'deployments', 'sample', 'apps'],\n",
       " ['row', 'level', 'security', 'postgresql', '9', '5'],\n",
       " ['perform', 'sentiment', 'analysis', 'lstms', 'using', 'tensorflow'],\n",
       " ['persisting', 'data', 'smarter', 'chatbot'],\n",
       " ['biginsights', 'cloud', 'analysts'],\n",
       " ['h2o', 'with', 'ibm', 'data', 'science', 'experience', 'dsx'],\n",
       " ['how', 'perform', 'logistic', 'regression', 'r'],\n",
       " ['importing',\n",
       "  'game',\n",
       "  'thrones',\n",
       "  'data',\n",
       "  'cloudant',\n",
       "  'simple',\n",
       "  'search',\n",
       "  'service'],\n",
       " ['getting', 'started', 'apache', 'mahout'],\n",
       " ['compose', 'enterprise', 'reloaded'],\n",
       " ['analysing',\n",
       "  'cloudant',\n",
       "  'json',\n",
       "  'runkit',\n",
       "  'javascript',\n",
       "  'notebooks',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['geofile', 'everything', 'radius', 'mongodb', 'geospatial', 'queries'],\n",
       " ['analyzing', 'streaming', 'data', 'kafka', 'topics'],\n",
       " ['mongo', 'mongo', 'data', 'moves', 'nifi'],\n",
       " ['create',\n",
       "  'connection',\n",
       "  'add',\n",
       "  'project',\n",
       "  'using',\n",
       "  'ibm',\n",
       "  'data',\n",
       "  'refinery'],\n",
       " ['mongodb', 'ransomware'],\n",
       " ['create', 'project', 'watson', 'machine', 'learning', 'dsx'],\n",
       " ['deep', 'learning', 'achievements', 'over', 'past', 'year'],\n",
       " ['why', 'managed', 'database', 'compose'],\n",
       " ['automating', 'web', 'analytics', 'python'],\n",
       " ['discover', 'catalog', 'govern', 'data', 'ibm', 'data', 'catalog'],\n",
       " ['create', 'replication', 'job'],\n",
       " ['21',\n",
       "  'must',\n",
       "  'know',\n",
       "  'data',\n",
       "  'science',\n",
       "  'interview',\n",
       "  'questions',\n",
       "  'answers'],\n",
       " ['build',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'architectures',\n",
       "  'with',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'modeler'],\n",
       " ['find', 'user', 'data', 'science'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'partial',\n",
       "  'indexing',\n",
       "  'improved',\n",
       "  'query',\n",
       "  'performance'],\n",
       " ['get', 'social', 'notebook', 'dsx'],\n",
       " ['integrate', 'dashdb', 'informatica', 'cloud'],\n",
       " ['imitation', 'learning', 'tensorflow', 'hopper', 'openai', 'gym'],\n",
       " ['shiny', 'data', 'scientist', 'best', 'friend'],\n",
       " ['70', 'amazing', 'free', 'data', 'sources', 'you', 'should', 'know'],\n",
       " ['calculate',\n",
       "  'moving',\n",
       "  'average',\n",
       "  'real',\n",
       "  'time',\n",
       "  'data',\n",
       "  'streams',\n",
       "  'designer'],\n",
       " ['libraries', 'tutorials'],\n",
       " ['sqlpro', 'postgres', 'keylord', 'redis'],\n",
       " ['predict',\n",
       "  'chronic',\n",
       "  'kidney',\n",
       "  'disease',\n",
       "  'using',\n",
       "  'spss',\n",
       "  'modeler',\n",
       "  'flows'],\n",
       " ['simulating',\n",
       "  'e',\n",
       "  't',\n",
       "  'or',\n",
       "  'insert',\n",
       "  'individual',\n",
       "  'file',\n",
       "  'object',\n",
       "  'storage',\n",
       "  'within',\n",
       "  'map',\n",
       "  'function',\n",
       "  'apache',\n",
       "  'spark'],\n",
       " ['webinar',\n",
       "  'april',\n",
       "  '11',\n",
       "  'thinking',\n",
       "  'inside',\n",
       "  'box',\n",
       "  'inside',\n",
       "  'data',\n",
       "  'frame'],\n",
       " ['cloudant', 'sync', 'ios', 'v1', '0', 'released'],\n",
       " ['package', 'development', 'devtools', 'cheat', 'sheet'],\n",
       " ['spark', 'sql', 'rapid', 'performance', 'evolution'],\n",
       " ['this', 'week', 'data', 'science'],\n",
       " ['how', 'circle', 'line', 'rogue', 'train', 'caught', 'data'],\n",
       " ['real',\n",
       "  'time',\n",
       "  'sentiment',\n",
       "  'analysis',\n",
       "  'twitter',\n",
       "  'hashtags',\n",
       "  'spark',\n",
       "  'pixiedust'],\n",
       " ['easy', 'json', 'loading', 'social', 'sharing', 'dsx', 'notebooks'],\n",
       " ['store', 'tweets', 'using', 'bluemix', 'node', 'red', 'cloudant', 'dashdb'],\n",
       " ['flexdashboard', 'interactive', 'dashboard', 'r'],\n",
       " ['working', 'data', 'flow', 'using', 'watson', 'data', 'apis'],\n",
       " ['score',\n",
       "  'predictive',\n",
       "  'model',\n",
       "  'built',\n",
       "  'ibm',\n",
       "  'spss',\n",
       "  'modeler',\n",
       "  'wml',\n",
       "  'dsx'],\n",
       " ['easy',\n",
       "  'access',\n",
       "  'all',\n",
       "  'points',\n",
       "  'interest',\n",
       "  'data',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['offline',\n",
       "  'sync',\n",
       "  'progressive',\n",
       "  'web',\n",
       "  'apps',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['improved', 'performance', 'redis', 'cache', 'mode', 'compose'],\n",
       " ['simple', 'search', 'service'],\n",
       " ['how',\n",
       "  'smart',\n",
       "  'catalog',\n",
       "  'turn',\n",
       "  'big',\n",
       "  'data',\n",
       "  'flood',\n",
       "  'ocean',\n",
       "  'opportunity'],\n",
       " ['connecting', 'r', 'compose', 'postgresql'],\n",
       " ['15', 'page', 'tutorial', 'r'],\n",
       " ['better', 'together', 'spss', 'data', 'science', 'experience'],\n",
       " ['predict', 'temperature', 'using', 'dashdb', 'python', 'r'],\n",
       " ['excel', 'file', 'loading', 'object', 'storage', 'python'],\n",
       " ['mongo', 'metrics', 'finding', 'happy', 'median'],\n",
       " ['datalayer',\n",
       "  'conference',\n",
       "  'online',\n",
       "  'schema',\n",
       "  'migrations',\n",
       "  'mysql',\n",
       "  'using',\n",
       "  'gh',\n",
       "  'ost'],\n",
       " ['visualizing', 'stripe', 'data', 'with', 'chartio'],\n",
       " ['metrics',\n",
       "  'maven',\n",
       "  'calculating',\n",
       "  'weighted',\n",
       "  'moving',\n",
       "  'average',\n",
       "  'postgresql'],\n",
       " ['magical', 'markov', 'chains'],\n",
       " ['missing', 'data', 'conundrum', 'exploration', 'imputation', 'techniques'],\n",
       " ['access', 'on', 'premises', 'db2', 'data', 'server', 'bluemix', 'cloud'],\n",
       " ['building', 'couchapps'],\n",
       " ['use', 'aginity', 'workbench', 'ibm', 'dashdb'],\n",
       " ['word2vec', 'data', 'products'],\n",
       " ['this', 'week', 'data', 'science', 'august', '16', '2016'],\n",
       " ['cloudant', '3', 'apache', 'couchdb', '2', '0'],\n",
       " ['load', 'analyze', 'public', 'data', 'set', 'dsx'],\n",
       " ['a', 'quick', 'guide', 'redis', '3', '2', 'geo', 'support'],\n",
       " ['using', 'postgresql', 'sqlalchemy'],\n",
       " ['cross', 'database', 'querying', 'compose', 'postgresql'],\n",
       " ['geofile',\n",
       "  'using',\n",
       "  'openstreetmap',\n",
       "  'data',\n",
       "  'compose',\n",
       "  'postgresql',\n",
       "  'part',\n",
       "  'i'],\n",
       " ['postgresql', 'connection', 'limit', 'control'],\n",
       " ['a', 'survey', 'books', 'apache', 'spark'],\n",
       " ['for',\n",
       "  'ai',\n",
       "  'get',\n",
       "  'creative',\n",
       "  'it',\n",
       "  'must',\n",
       "  'learn',\n",
       "  'rules',\n",
       "  'then',\n",
       "  'how',\n",
       "  'break',\n",
       "  'em'],\n",
       " ['simple', 'oauth', 'with', 'mongodb', 'mysql'],\n",
       " ['index', 'array', 'elements', 'query', 'json'],\n",
       " ['the', 'database', 'tool', 'elixir', 'phoenix'],\n",
       " ['data', 'migration', 'transformation', 'tools'],\n",
       " ['data', 'visualization', 'playbook', 'telling', 'data', 'story'],\n",
       " ['the', 'power', 'machine', 'learning', 'spark'],\n",
       " ['visual', 'information', 'theory'],\n",
       " ['10', 'essential', 'algorithms', 'for', 'machine', 'learning', 'engineers'],\n",
       " ['nips', '2016', 'day', '2', 'highlights'],\n",
       " ['this', 'week', 'data', 'science', 'march', '7', '2017'],\n",
       " ['may', '2016', 'scripts', 'week'],\n",
       " ['from', 'python', 'nested', 'lists', 'multidimensional', 'numpy', 'arrays'],\n",
       " ['the',\n",
       "  'most',\n",
       "  'popular',\n",
       "  'search',\n",
       "  'term',\n",
       "  'sxsw',\n",
       "  'according',\n",
       "  'our',\n",
       "  'chatbot'],\n",
       " ['pixiedust', '1', '0', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['developing', 'ibm', 'streaming', 'analytics', 'service'],\n",
       " ['you',\n",
       "  'may',\n",
       "  'get',\n",
       "  'pwned',\n",
       "  'at',\n",
       "  'least',\n",
       "  'protect',\n",
       "  'password',\n",
       "  'bcrypt'],\n",
       " ['rapidly', 'build', 'machine', 'learning', 'flow', 'dsx'],\n",
       " ['mobile', 'apps', 'offline', 'online'],\n",
       " ['asynchronous', 'joins', 'using', 'rabbitmq'],\n",
       " ['making',\n",
       "  'sense',\n",
       "  'bias',\n",
       "  'variance',\n",
       "  'trade',\n",
       "  'deep',\n",
       "  'reinforcement',\n",
       "  'learning'],\n",
       " ['this', 'week', 'data', 'science', 'september', '20', '2016'],\n",
       " ['pouchdb',\n",
       "  'swiss',\n",
       "  'army',\n",
       "  'knife',\n",
       "  'database',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['simple', 'service', 'registry'],\n",
       " ['store', 'result', 'sets', 'materialized', 'views', 'postgresql'],\n",
       " ['10', 'piece', 'advice', 'beginner', 'data', 'scientist'],\n",
       " ['easy', 'frontends', 'simple', 'search', 'api', 'using', 'got', 'data'],\n",
       " ['deploying', 'full', 'stack', 'node', 'j', 'application', 'ibm', 'bluemix'],\n",
       " ['seven',\n",
       "  'databases',\n",
       "  'seven',\n",
       "  'days',\n",
       "  'cloud',\n",
       "  'data',\n",
       "  'services',\n",
       "  'journey'],\n",
       " ['spark',\n",
       "  'based',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'tool',\n",
       "  'capturing',\n",
       "  'word',\n",
       "  'meaning'],\n",
       " ['talking', 'scylladb', 'cto', 'avi', 'kivity'],\n",
       " ['httr', '1', '2', '0'],\n",
       " ['storing', 'network', 'addresses', 'using', 'postgresql'],\n",
       " ['geofile', 'spatial', 'reference', 'systems', 'databases'],\n",
       " ['hurricane', 'how', 'to'],\n",
       " ['introducing', 'cloudant', 'geospatial'],\n",
       " ['build', 'predictive', 'analytic', 'model'],\n",
       " ['schemas', 'couchdb'],\n",
       " ['sharing',\n",
       "  'non',\n",
       "  'public',\n",
       "  'data',\n",
       "  'jupyter',\n",
       "  'notebook',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['move', 'toy', 'car', 'mind'],\n",
       " ['getting', 'started', 'elasticsearch', 'node', 'j', 'part', '2'],\n",
       " ['mobile',\n",
       "  'web',\n",
       "  'apps',\n",
       "  'pouchdb',\n",
       "  'angularjs',\n",
       "  'node',\n",
       "  'j',\n",
       "  'ibm',\n",
       "  'cloudant'],\n",
       " ['working', 'premise', 'database', 'step', 'step'],\n",
       " ['a', 'glimpse', 'inside', 'mind', 'data', 'scientist'],\n",
       " ['using',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'parallel',\n",
       "  'processing',\n",
       "  'framework',\n",
       "  'accessing',\n",
       "  'rest',\n",
       "  'based',\n",
       "  'data',\n",
       "  'service'],\n",
       " ['are', 'your', 'predictive', 'models', 'like', 'broken', 'clocks'],\n",
       " ['seti', 'data', 'publicly', 'available', 'ibm'],\n",
       " ['variational', 'auto', 'encoder', 'frey', 'face', 'using', 'kera'],\n",
       " ['from', 'machine', 'learning', 'learning', 'machine', 'dinesh', 'nirmal'],\n",
       " ['load', 'data', 'rstudio', 'analysis', 'dsx'],\n",
       " ['tidy', 'data', 'in', 'python'],\n",
       " ['announcing', 'data', 'browser', 'janusgraph'],\n",
       " ['making', 'data', 'science', 'team', 'sport'],\n",
       " ['building',\n",
       "  'secure',\n",
       "  'distributed',\n",
       "  'javascript',\n",
       "  'microservices',\n",
       "  'rabbitmq',\n",
       "  'senecajs'],\n",
       " ['python',\n",
       "  'if',\n",
       "  'statements',\n",
       "  'explained',\n",
       "  'python',\n",
       "  'for',\n",
       "  'data',\n",
       "  'science',\n",
       "  'basics',\n",
       "  '4'],\n",
       " ['powering', 'social', 'feed', 'timeline', 'elasticsearch'],\n",
       " ['easier', 'java', 'connection', 'mongodb', 'compose'],\n",
       " ['export', 'cloudant', 'json', 'csv', 'rss', 'ical'],\n",
       " ['biginsights', 'sample', 'scripts'],\n",
       " ['caching', 'cloudant', 'requests', 'cachemachine'],\n",
       " ['authenticating', 'node', 'red', 'using', 'jsonwebtoken', 'part', '2'],\n",
       " ['postgraphql', 'postgresql', 'meet', 'graphql'],\n",
       " ['your', 'weather', 'forecast', 'python', 'notebook'],\n",
       " ['making', 'smart', 'business', 'chatbot', 'part', '2'],\n",
       " ['governance', 'overview', 'ibm', 'data', 'catalog'],\n",
       " ['connecting', 'application', 'compose', 'mysql'],\n",
       " ['database', 'management', 'tools', 'compose', 'mysql'],\n",
       " ['empirical', 'bayes', 'multiple', 'sample', 'size'],\n",
       " ['effectively', 'using', 'matplotlib'],\n",
       " ['handling',\n",
       "  'failure',\n",
       "  'successfully',\n",
       "  'rabbitmq',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['10',\n",
       "  'data',\n",
       "  'science',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'ai',\n",
       "  'podcasts',\n",
       "  'you',\n",
       "  'must',\n",
       "  'listen',\n",
       "  'to'],\n",
       " ['interactive', 'time', 'series', 'dygraphs'],\n",
       " ['getting', 'connected', 'rabbitmq', 'elasticsearch'],\n",
       " ['cloud', 'data', 'services'],\n",
       " ['quick', 'guide', 'build', 'recommendation', 'engine', 'python'],\n",
       " ['java', 'let', 'encrypt', 'certificate'],\n",
       " ['compose', 'rabbitmq', 'beta'],\n",
       " ['command', 'line', 'tool', 'cloudant', 'couchdb'],\n",
       " ['building', 'instant', 'restful', 'api', 'mongodb', 'restheart'],\n",
       " ['10',\n",
       "  'powerful',\n",
       "  'features',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'platform',\n",
       "  'no',\n",
       "  'coding',\n",
       "  'necessary'],\n",
       " ['on', 'calculating', 'auc'],\n",
       " ['a',\n",
       "  'dramatic',\n",
       "  'tour',\n",
       "  'python',\n",
       "  'data',\n",
       "  'visualization',\n",
       "  'landscape',\n",
       "  'including',\n",
       "  'ggplot',\n",
       "  'altair'],\n",
       " ['moving',\n",
       "  'data',\n",
       "  'dynamodb',\n",
       "  'cloudant',\n",
       "  'couchdb',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['reintroducing', 'simple', 'search', 'service'],\n",
       " ['blogging', 'without', 'hosting', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['eye', 'candy', 'cloudant', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['machine', 'learning', 'enterprise'],\n",
       " ['sentiment', 'analysis', 'twitter', 'hashtags'],\n",
       " ['connecting', 'compose', 'mysql'],\n",
       " ['simple', 'website', 'metrics'],\n",
       " ['making', 'compose', 'customer', 'case', 'study', 'human', 'design'],\n",
       " ['machine', 'learning', 'everyone'],\n",
       " ['collaborate', 'project', 'dsx'],\n",
       " ['this', 'week', 'data', 'science', 'august', '23', '2016'],\n",
       " ['interview',\n",
       "  'christopher',\n",
       "  'quinones',\n",
       "  'newest',\n",
       "  'graph',\n",
       "  'database',\n",
       "  'janusgraph'],\n",
       " ['use', 'machine', 'learning', 'library'],\n",
       " ['environment',\n",
       "  'variable',\n",
       "  'keeping',\n",
       "  'secret',\n",
       "  'secret',\n",
       "  'node',\n",
       "  'j',\n",
       "  'app',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['getting', 'distance', 'using', 'redis', 'postgresql'],\n",
       " ['machine', 'learning', 'exercises', 'in', 'python', 'part', '1'],\n",
       " ['generative', 'adversarial', 'networks', 'gans'],\n",
       " ['add',\n",
       "  'custom',\n",
       "  'alexa',\n",
       "  'skill',\n",
       "  'openwhisk',\n",
       "  'cloudant',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['what', 'i', 'learned', 'pycon', 'spark', 'summit'],\n",
       " ['offline', 'first', 'fomo'],\n",
       " ['girl', 'develop', 'it', 'leadership', 'summit', 'recap'],\n",
       " ['building', 'javascript', 'microservices', 'senecajs', 'compose'],\n",
       " ['avoid', 'storing', 'data', 'inside', 'admin', 'when', 'using', 'mongodb'],\n",
       " ['keeping', 'data', 'warehouse', 'infrastructure', 'way'],\n",
       " ['using', 'rstudio', 'ibm', 'data', 'science', 'experience'],\n",
       " ['plug', 'in', 'cloudant', 'node', 'j', 'library', 'v1', '5'],\n",
       " ['node', 'red'],\n",
       " ['code',\n",
       "  'walkthrough',\n",
       "  'ibm',\n",
       "  'mobilefirst',\n",
       "  'platform',\n",
       "  'bluemix',\n",
       "  'hosted',\n",
       "  'acme',\n",
       "  'apparel',\n",
       "  'application'],\n",
       " ['what',\n",
       "  'smote',\n",
       "  'imbalanced',\n",
       "  'class',\n",
       "  'setting',\n",
       "  'e',\n",
       "  'g',\n",
       "  'fraud',\n",
       "  'detection'],\n",
       " ['building', 'secure', 'instant', 'api', 'restheart', 'compose'],\n",
       " ['add', 'data', 'asset', 'catalog', 'using', 'ibm', 'data', 'catalog'],\n",
       " ['this', 'week', 'data', 'science', 'august', '09', '2016'],\n",
       " ['analyzing',\n",
       "  'salesforce',\n",
       "  'data',\n",
       "  'looker',\n",
       "  'a',\n",
       "  'salesforce',\n",
       "  'bi',\n",
       "  'solution',\n",
       "  'dashdb',\n",
       "  'cloudant',\n",
       "  'looker'],\n",
       " ['getting', 'started', 'elasticsearch', 'using', 'compose'],\n",
       " ['turn', 'small', 'data', 'into', 'smart', 'data', 'part', '1'],\n",
       " ['voice', 'interconnect', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['machine', 'learning', 'science', 'choosing'],\n",
       " ['app', 'store', 'give', 'hope', 'indie', 'developers', 'again'],\n",
       " ['build', 'sql', 'queries', 'scala', 'notebook', 'using', 'apache', 'spark'],\n",
       " ['this', 'week', 'data', 'science', 'october', '05', '2016'],\n",
       " ['the', 'center', 'your', 'data', 'universe'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '5', 'etcd'],\n",
       " ['leverage', 'dashdb', 'cognos', 'business', 'intelligence'],\n",
       " ['authorized', 'curl', 'k', 'acurl'],\n",
       " ['access', 'documentation', 'support', 'resources'],\n",
       " ['querying',\n",
       "  'your',\n",
       "  'pouchdb',\n",
       "  'database',\n",
       "  'sql',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['aspiring',\n",
       "  'data',\n",
       "  'scientists',\n",
       "  'start',\n",
       "  'learn',\n",
       "  'statistics',\n",
       "  '6',\n",
       "  'book'],\n",
       " ['use', 'cloudant', 'spark', 'connector', 'python', 'notebook'],\n",
       " ['optimizing', 'mongodb', 'queries', 'elasticsearch'],\n",
       " ['pearson', 'correlation', 'aggregation', 'sparksql'],\n",
       " ['navigating', 'nosql'],\n",
       " ['schema', 'migration', 'alembic', 'python', 'postgresql'],\n",
       " ['humans',\n",
       "  'v',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'building',\n",
       "  'rock',\n",
       "  'paper',\n",
       "  'scissors',\n",
       "  'game'],\n",
       " ['example', 'chrome', 'extensions', 'using', 'pouchdb'],\n",
       " ['create', 'serverless', 'watson', 'powered', 'chatbot', 'business'],\n",
       " ['scaling', 'existing', 'php', 'app', 'rabbitmq'],\n",
       " ['best', 'practices', 'custom', 'models', 'watson', 'visual', 'recognition'],\n",
       " ['making', 'data', 'pretty', 'postgresql'],\n",
       " ['enjoy', 'python', '3', '5', 'jupyter', 'notebooks'],\n",
       " ['running', 'pouchdb', 'web', 'worker'],\n",
       " ['r', 'markdown', 'reference', 'guide'],\n",
       " ['analyze', 'starcraft', 'ii', 'replay', 'jupyter', 'notebooks'],\n",
       " ['build',\n",
       "  'scalable',\n",
       "  'webhooks',\n",
       "  'queue',\n",
       "  'workers',\n",
       "  'setup',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['mapreduce', 'explained'],\n",
       " ['cleaning',\n",
       "  'swamp',\n",
       "  'turn',\n",
       "  'data',\n",
       "  'lake',\n",
       "  'source',\n",
       "  'crystal',\n",
       "  'clear',\n",
       "  'insight'],\n",
       " ['time', 'series', 'analysis', 'using', 'max', 'min', 'neuroscience'],\n",
       " ['introduction', 'compose', 'mongodb'],\n",
       " ['this', 'week', 'data', 'science', 'february', '21', '2017'],\n",
       " ['analyze', 'traffic', 'data', 'city', 'san', 'francisco'],\n",
       " ['turn', 'small', 'data', 'into', 'smart', 'data', 'part', '2'],\n",
       " ['webizing', 'database', 'linked', 'data', 'json', 'ld', 'cloudant'],\n",
       " ['how', 'write', 'first', 'loop', 'r'],\n",
       " ['an', 'ibm', 'graph', 'client', 'library', 'node', 'j'],\n",
       " ['stacking',\n",
       "  'multiple',\n",
       "  'custom',\n",
       "  'models',\n",
       "  'watson',\n",
       "  'visual',\n",
       "  'recognition'],\n",
       " ['overfitting',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'what',\n",
       "  'it',\n",
       "  'is',\n",
       "  'how',\n",
       "  'prevent',\n",
       "  'it'],\n",
       " ['sample', 'python', 'notebook', 'precipitation', 'analysis'],\n",
       " ['load', 'data', 'desktop', 'dashdb'],\n",
       " ['faster', 'performance', 'unlogged', 'tables', 'postgresql'],\n",
       " ['nips', '2016', 'day', '1', 'highlights'],\n",
       " ['statistical', 'bias', 'types', 'explained'],\n",
       " ['building',\n",
       "  'ordering',\n",
       "  'application',\n",
       "  'watson',\n",
       "  'ai',\n",
       "  'postgresql',\n",
       "  'part',\n",
       "  '1'],\n",
       " ['10',\n",
       "  'data',\n",
       "  'science',\n",
       "  'podcasts',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'right',\n",
       "  'now'],\n",
       " ['do', 'know', 'compose', 'proxy', 'database', 'connection'],\n",
       " ['probabilistic',\n",
       "  'graphical',\n",
       "  'models',\n",
       "  'tutorial',\n",
       "  'part',\n",
       "  '1',\n",
       "  'stats',\n",
       "  'bots'],\n",
       " ['web', 'picks', 'week', '2', 'october', '2017'],\n",
       " ['blogging', 'with', 'brunel'],\n",
       " ['building',\n",
       "  'ordering',\n",
       "  'application',\n",
       "  'watson',\n",
       "  'ai',\n",
       "  'postgresql',\n",
       "  'part',\n",
       "  'ii'],\n",
       " ['don', 'overlook', 'simpler', 'technique', 'algorithm'],\n",
       " ['use', 'nifi', 'lessen', 'friction', 'moving', 'data'],\n",
       " ['perform', 'market', 'basket', 'analysis', 'using', 'dashdb', 'r'],\n",
       " ['forgetting',\n",
       "  'past',\n",
       "  'learn',\n",
       "  'future',\n",
       "  'long',\n",
       "  'short',\n",
       "  'term',\n",
       "  'memory',\n",
       "  'neural',\n",
       "  'networks',\n",
       "  'time',\n",
       "  'series',\n",
       "  'prediction'],\n",
       " ['use', 'all', 'databases', 'part', '2'],\n",
       " ['mobile', 'app', 'webinar', 'demo'],\n",
       " ['connecting', 'php', 'compose', 'mysql', 'bluemix'],\n",
       " ['interactive', 'web', 'apps', 'shiny', 'cheat', 'sheet'],\n",
       " ['breaking',\n",
       "  '80',\n",
       "  '20',\n",
       "  'rule',\n",
       "  'how',\n",
       "  'data',\n",
       "  'catalog',\n",
       "  'transform',\n",
       "  'data',\n",
       "  'scientist',\n",
       "  'productivity'],\n",
       " ['use',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'library',\n",
       "  'ibm',\n",
       "  'analytics',\n",
       "  'apache',\n",
       "  'spark'],\n",
       " ['geojson', 'database', 'cloudant', 'mapbox'],\n",
       " ['seven', 'databases', 'seven', 'days', 'day', '6', 'ibm', 'graph'],\n",
       " ['a', 'guide', 'convolution', 'arithmetic', 'deep', 'learning'],\n",
       " ['simple', 'metrics', 'tutorial', 'part', '2'],\n",
       " ['neural', 'language', 'modeling', 'from', 'scratch', 'part', '1'],\n",
       " ['tidyr', '0', '4', '0'],\n",
       " ['introducing', 'simple', 'notification', 'service'],\n",
       " ['pouchdb', 'in', 'browser', 'database', 'that', 'replicates'],\n",
       " ['open', 'crime', 'data', 'free', 'all'],\n",
       " ['an', 'attempt', 'understand', 'boosting', 'algorithm'],\n",
       " ['query', 'the', 'search', 'index'],\n",
       " ['the', 'random', 'forest', 'algorithm'],\n",
       " ['jupyter', 'ipython', 'notebook', 'feature'],\n",
       " ['build', 'spark', 'sql', 'queries'],\n",
       " ['making', 'smart', 'business', 'chatbot', 'part', '1'],\n",
       " ['cloudant', 'search', 'geo', 'example'],\n",
       " ['working', 'with', 'ibm', 'cloud', 'object', 'storage', 'in', 'python'],\n",
       " ['using', 'machine', 'learning', 'predict', 'baseball', 'injuries'],\n",
       " ['search', 'lobbyist', 'disclosures'],\n",
       " ['building', 'dynamic', 'configuration', 'service', 'etcd', 'python'],\n",
       " ['diff', 'database', 'couchdiff', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['land', 'stripe', 'data', 'ibm', 'dashdb', 'cloud', 'data', 'warehouse'],\n",
       " ['use', 'new', 'cloudant', 'query'],\n",
       " ['ibm', 'cloudant', 'overview', 'nosql', 'database', 'service'],\n",
       " ['tell',\n",
       "  'me',\n",
       "  'something',\n",
       "  'i',\n",
       "  'don',\n",
       "  'know',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab',\n",
       "  'medium'],\n",
       " ['watson', 'speech', 'text', 'services', 'tl', 'dr', 'need', 'apply'],\n",
       " ['everything', 'radius', 'postgis'],\n",
       " ['visualizing', 'compose', 'postgresql', 'data', 'leftronic'],\n",
       " ['customer', 'interloop', 'making', 'most', 'compose'],\n",
       " ['compose',\n",
       "  'mysql',\n",
       "  'compose',\n",
       "  'scylladb',\n",
       "  'new',\n",
       "  'compose',\n",
       "  'database',\n",
       "  'bluemix'],\n",
       " ['datalayer', 'exposed', 'antonio', 'chavez', 'why', 'we', 'left', 'mongodb'],\n",
       " ['build', 'sql', 'query', 'apache', 'spark', 'dsx'],\n",
       " ['talent', 'v', 'luck', 'role', 'randomness', 'success', 'failure'],\n",
       " ['reading', 'writing'],\n",
       " ['time', 'series', 'anomaly', 'detection', 'algorithms', 'stats', 'bots'],\n",
       " ['tidyr', '0', '5', '0'],\n",
       " ['how', 'use', 'version', 'control', 'github', 'rstudio', 'within', 'dsx'],\n",
       " ['short', 'notice', 'serverless', 'conference'],\n",
       " ['pseudo', 'labeling', 'simple', 'semi', 'supervised', 'learning', 'method'],\n",
       " ['workflow', 'r'],\n",
       " ['load',\n",
       "  'cloudant',\n",
       "  'data',\n",
       "  'apache',\n",
       "  'spark',\n",
       "  'using',\n",
       "  'python',\n",
       "  'notebook'],\n",
       " ['making', 'data', 'cleaning', 'simple', 'sparkling', 'data', 'library'],\n",
       " ['unstructured',\n",
       "  'structured',\n",
       "  'data',\n",
       "  'versus',\n",
       "  'repetitive',\n",
       "  'non',\n",
       "  'repetitive'],\n",
       " ['who', 'limit', 'rate', 'limiter', 'ibm', 'watson', 'data', 'lab', 'medium'],\n",
       " ['formatted', 'sql', 'python', 'psycopg', 'mogrify'],\n",
       " ['deep', 'learning', 'from', 'scratch', 'i', 'computational', 'graphs'],\n",
       " ['a', 'new', 'version', 'dt', '0', '2', 'cran'],\n",
       " ['a',\n",
       "  'fast',\n",
       "  'on',\n",
       "  'disk',\n",
       "  'format',\n",
       "  'data',\n",
       "  'frames',\n",
       "  'r',\n",
       "  'python',\n",
       "  'powered',\n",
       "  'apache',\n",
       "  'arrow'],\n",
       " ['interview', 'sean', 'li', 'new', 'apache', 'spark', 'committer'],\n",
       " ['discover', 'hidden', 'facebook', 'usage', 'insight'],\n",
       " ['extract', 'export', 'dashdb', 'data', 'csv', 'file'],\n",
       " ['customer', 'readme', 'conquering', 'data', 'layer'],\n",
       " ['new', 'compose', 'horizontal', 'scaling', 'redis', 'scaling', 'control'],\n",
       " ['big', 'data', 'better', 'data'],\n",
       " ['what', 'systemml', 'why', 'relevant'],\n",
       " ['apache', 'spark', 'sql', 'analyzer', 'resolves', 'order', 'column'],\n",
       " ['why', 'developer', 'experience', 'matters', 'cloud', 'expo', '2015'],\n",
       " ['shiny', '0', '12', 'interactive', 'plots', 'ggplot2'],\n",
       " ['why', 'even', 'moth', 'brain', 'smarter', 'ai'],\n",
       " ['simple', 'data', 'pipe', 'connector'],\n",
       " ['a', 'plethora', 'open', 'data', 'repositories', 'e', 'thousand'],\n",
       " ['leaflet', 'interactive', 'web', 'map', 'r'],\n",
       " ['biginsights', 'cloud', 'data', 'scientists'],\n",
       " ['brunel', 'interactive', 'visualization', 'jupyter', 'notebook'],\n",
       " ['using', 'dsx', 'notebook', 'analyze', 'github', 'data'],\n",
       " ['understanding',\n",
       "  'empirical',\n",
       "  'bayes',\n",
       "  'estimation',\n",
       "  'using',\n",
       "  'baseball',\n",
       "  'statistic'],\n",
       " ['interview', 'leveraging', 'technology', 'and', 'd3', 'js'],\n",
       " ['beyond', 'parallelize', 'collect'],\n",
       " ['data', 'visualization', 'r', 'scrum', 'metric'],\n",
       " ['how', 'get', 'backup', 'compose', 'api', 'node', 'j'],\n",
       " ['our', 'first', 'offline', 'first', 'camp', '3'],\n",
       " ['data', 'visualization', 'playbook', 'revisiting', 'basics'],\n",
       " ['faster', 'operations', 'jsonb', 'data', 'type', 'postgresql'],\n",
       " ['use', 'primary', 'index'],\n",
       " ['self', 'service', 'data', 'preparation', 'ibm', 'data', 'refinery'],\n",
       " ['ml', 'algorithm', 'learning', 'machine'],\n",
       " ['shiny', '0', '13', '0'],\n",
       " ['flightpredict', 'ii', 'the', 'sequel', 'ibm', 'watson', 'data', 'lab'],\n",
       " ['launching', 'restheart', 'production'],\n",
       " ['defensive', 'coding', 'map', 'index', 'function'],\n",
       " ['create', 'project', 'dsx'],\n",
       " ['recent', 'trend', 'recommender', 'system'],\n",
       " ['this', 'week', 'data', 'science', 'november', '22', '2016'],\n",
       " ['the', 'data', 'science', 'process'],\n",
       " ['using', 'couchimport', 'load', 'json', 'data', 'cloudant'],\n",
       " ['apache', 'spark', 'new', 'engine', 'genomics'],\n",
       " ['session',\n",
       "  'recap',\n",
       "  'save',\n",
       "  'world',\n",
       "  'offline',\n",
       "  'first',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['making', 'most', 'compose', 'customer', 'c2g', 'consulting'],\n",
       " ['logshare'],\n",
       " ['super', 'fast', 'string', 'matching', 'python'],\n",
       " ['identify', 'useful', 'http', 'api', 'tools'],\n",
       " ['redis', 'go', 'how', 'build', 'chat', 'application'],\n",
       " ['the', 'data', 'processing', 'inequality'],\n",
       " ['a', 'day', 'life', 'data', 'engineer'],\n",
       " ['r', 'data', 'science'],\n",
       " ['realtime',\n",
       "  'infrastucture',\n",
       "  'made',\n",
       "  'simple',\n",
       "  'ibm',\n",
       "  'watson',\n",
       "  'data',\n",
       "  'lab'],\n",
       " ['accessing', 'db2', 'prem', 'database', 'ibm', 'bluemix', 'cloud'],\n",
       " ['mastering', 'redis', 'high', 'availability', 'blocking', 'connection'],\n",
       " ['this', 'week', 'data', 'science', 'january', '10', '2017'],\n",
       " ['bach', 'updated', 'support', 'streamlined'],\n",
       " ['building', 'mobilefirst', 'app', 'ibm', 'bluemix'],\n",
       " ['configuring', 'apache', 'spark', 'sql', 'context'],\n",
       " ['using', 'query', 'string', 'queries', 'elasticsearch'],\n",
       " ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_name_tokenized = []\n",
    "doc_name_tokenized = [tokenize(str(name)) for name in ibm_content]\n",
    "doc_name_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b1e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0356c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 695332\n",
      "Number of 1s: 39\n",
      "Number of other values: 4757\n",
      "Total elements in the matrix: 700128\n"
     ]
    }
   ],
   "source": [
    "# Count the number of 1s (non-zero elements that are 1)\n",
    "ones_count = np.sum(X == 1)\n",
    "\n",
    "# Count the number of non-zero elements (sparse matrices store only non-zero elements)\n",
    "non_zero_count = X.count_nonzero()\n",
    "\n",
    "# Total number of elements in the matrix\n",
    "total_elements = X.shape[0] * X.shape[1]\n",
    "\n",
    "# Number of 0s is the total elements minus the non-zero elements\n",
    "zeros_count = total_elements - non_zero_count\n",
    "\n",
    "# Number of 'other' elements are non-zero elements that are not 1\n",
    "others_count = non_zero_count - ones_count\n",
    "\n",
    "print(f\"Number of 0s: {zeros_count}\")\n",
    "print(f\"Number of 1s: {ones_count}\")\n",
    "print(f\"Number of other values: {others_count}\")\n",
    "print(f\"Total elements in the matrix: {total_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8f3dce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_model(df_content):\n",
    "    \"\"\"\n",
    "    Builds a content-based similarity model using TF-IDF and cosine similarity.\n",
    "    \n",
    "    The function performs the following steps:\n",
    "    1. Vectorizes the document titles using TF-IDF.\n",
    "    2. Computes the cosine similarity matrix between document titles.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    cosine_sim_df: DataFrame\n",
    "        A DataFrame containing the cosine similarity scores between document titles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract document titles from the df\n",
    "    doc_name = df_content['doc_full_name'].values.tolist()\n",
    "\n",
    "    # Create a TF-IDF vectorizer and fit it to the document titles\n",
    "    vectorizer = TfidfVectorizer(tokenizer=tokenize, min_df=2, max_df=0.95)\n",
    "    X = vectorizer.fit_transform(doc_name)\n",
    "\n",
    "    # Compute the cosine similarity matrix between all document vectors\n",
    "    cosine_sim = cosine_similarity(X)\n",
    "\n",
    "    # Convert the similarity matrix into a df\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim, index=doc_name, columns=doc_name)\n",
    "\n",
    "    # Return the cosine similarity DataFrame\n",
    "    return cosine_sim_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "edfaba97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detect Malfunctioning IoT Sensors with Streaming Analytics</th>\n",
       "      <th>Communicating data science: A guide to presenting your work</th>\n",
       "      <th>This Week in Data Science (April 18, 2017)</th>\n",
       "      <th>DataLayer Conference: Boost the performance of your distributed database</th>\n",
       "      <th>Analyze NY Restaurant data using Spark in DSX</th>\n",
       "      <th>Browsing PostgreSQL Data with Compose</th>\n",
       "      <th>Upgrading your PostgreSQL to 9.5</th>\n",
       "      <th>Data Wrangling at Slack</th>\n",
       "      <th>Data Science Bowl 2017</th>\n",
       "      <th>Using Apache Spark to predict attack vectors among billions of users and trillions of events</th>\n",
       "      <th>...</th>\n",
       "      <th>Mapping All the Things with Python – IBM Watson Data Lab – Medium</th>\n",
       "      <th>Use IBM Data Science Experience to Read and Write Data Stored on Amazon S3</th>\n",
       "      <th>Use IoT data in Streams Designer for billing and alerts</th>\n",
       "      <th>Mapping Points with Folium</th>\n",
       "      <th>A Speed Guide To Redis Lua Scripting</th>\n",
       "      <th>A look under the covers of PouchDB-find</th>\n",
       "      <th>A comparison of logistic regression and naive Bayes</th>\n",
       "      <th>What I Learned Implementing a Classifier from Scratch in Python · Jean-Nicholas Hould</th>\n",
       "      <th>Use dashDB with Spark</th>\n",
       "      <th>Jupyter Notebooks with Scala, Python, or R Kernels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detect Malfunctioning IoT Sensors with Streaming Analytics</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communicating data science: A guide to presenting your work</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045340</td>\n",
       "      <td>0.087390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052546</td>\n",
       "      <td>0.282969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.141384</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This Week in Data Science (April 18, 2017)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>0.068645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041275</td>\n",
       "      <td>0.526122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031470</td>\n",
       "      <td>0.111058</td>\n",
       "      <td>0.033845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataLayer Conference: Boost the performance of your distributed database</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analyze NY Restaurant data using Spark in DSX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045340</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>0.067692</td>\n",
       "      <td>0.170562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.052428</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A look under the covers of PouchDB-find</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A comparison of logistic regression and naive Bayes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What I Learned Implementing a Classifier from Scratch in Python · Jean-Nicholas Hould</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use dashDB with Spark</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>0.229955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter Notebooks with Scala, Python, or R Kernels</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 1051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Detect Malfunctioning IoT Sensors with Streaming Analytics  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                                1.0            \n",
       "Communicating data science: A guide to presenti...                                                0.0            \n",
       "This Week in Data Science (April 18, 2017)                                                        0.0            \n",
       "DataLayer Conference: Boost the performance of ...                                                0.0            \n",
       "Analyze NY Restaurant data using Spark in DSX                                                     0.0            \n",
       "...                                                                                               ...            \n",
       "A look under the covers of PouchDB-find                                                           0.0            \n",
       "A comparison of logistic regression and naive B...                                                0.0            \n",
       "What I Learned Implementing a Classifier from S...                                                0.0            \n",
       "Use dashDB with Spark                                                                             0.0            \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                                0.0            \n",
       "\n",
       "                                                    Communicating data science: A guide to presenting your work  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000             \n",
       "Communicating data science: A guide to presenti...                                           1.000000             \n",
       "This Week in Data Science (April 18, 2017)                                                   0.148876             \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000             \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.045340             \n",
       "...                                                                                               ...             \n",
       "A look under the covers of PouchDB-find                                                      0.000000             \n",
       "A comparison of logistic regression and naive B...                                           0.000000             \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000             \n",
       "Use dashDB with Spark                                                                        0.000000             \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000             \n",
       "\n",
       "                                                    This Week in Data Science (April 18, 2017)  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                    0.000000   \n",
       "Communicating data science: A guide to presenti...                                    0.148876   \n",
       "This Week in Data Science (April 18, 2017)                                            1.000000   \n",
       "DataLayer Conference: Boost the performance of ...                                    0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                         0.035614   \n",
       "...                                                                                        ...   \n",
       "A look under the covers of PouchDB-find                                               0.000000   \n",
       "A comparison of logistic regression and naive B...                                    0.000000   \n",
       "What I Learned Implementing a Classifier from S...                                    0.000000   \n",
       "Use dashDB with Spark                                                                 0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                    0.000000   \n",
       "\n",
       "                                                    DataLayer Conference: Boost the performance of your distributed database  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                                0.0                          \n",
       "Communicating data science: A guide to presenti...                                                0.0                          \n",
       "This Week in Data Science (April 18, 2017)                                                        0.0                          \n",
       "DataLayer Conference: Boost the performance of ...                                                1.0                          \n",
       "Analyze NY Restaurant data using Spark in DSX                                                     0.0                          \n",
       "...                                                                                               ...                          \n",
       "A look under the covers of PouchDB-find                                                           0.0                          \n",
       "A comparison of logistic regression and naive B...                                                0.0                          \n",
       "What I Learned Implementing a Classifier from S...                                                0.0                          \n",
       "Use dashDB with Spark                                                                             0.0                          \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                                0.0                          \n",
       "\n",
       "                                                    Analyze NY Restaurant data using Spark in DSX  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                       0.000000   \n",
       "Communicating data science: A guide to presenti...                                       0.045340   \n",
       "This Week in Data Science (April 18, 2017)                                               0.035614   \n",
       "DataLayer Conference: Boost the performance of ...                                       0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                            1.000000   \n",
       "...                                                                                           ...   \n",
       "A look under the covers of PouchDB-find                                                  0.000000   \n",
       "A comparison of logistic regression and naive B...                                       0.000000   \n",
       "What I Learned Implementing a Classifier from S...                                       0.000000   \n",
       "Use dashDB with Spark                                                                    0.182155   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                       0.000000   \n",
       "\n",
       "                                                    Browsing PostgreSQL Data with Compose  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                               0.000000   \n",
       "Communicating data science: A guide to presenti...                               0.087390   \n",
       "This Week in Data Science (April 18, 2017)                                       0.068645   \n",
       "DataLayer Conference: Boost the performance of ...                               0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                    0.072029   \n",
       "...                                                                                   ...   \n",
       "A look under the covers of PouchDB-find                                          0.000000   \n",
       "A comparison of logistic regression and naive B...                               0.000000   \n",
       "What I Learned Implementing a Classifier from S...                               0.000000   \n",
       "Use dashDB with Spark                                                            0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                               0.000000   \n",
       "\n",
       "                                                    Upgrading your PostgreSQL to 9.5  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                               0.0   \n",
       "Communicating data science: A guide to presenti...                               0.0   \n",
       "This Week in Data Science (April 18, 2017)                                       0.0   \n",
       "DataLayer Conference: Boost the performance of ...                               0.0   \n",
       "Analyze NY Restaurant data using Spark in DSX                                    0.0   \n",
       "...                                                                              ...   \n",
       "A look under the covers of PouchDB-find                                          0.0   \n",
       "A comparison of logistic regression and naive B...                               0.0   \n",
       "What I Learned Implementing a Classifier from S...                               0.0   \n",
       "Use dashDB with Spark                                                            0.0   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                               0.0   \n",
       "\n",
       "                                                    Data Wrangling at Slack  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                 0.000000   \n",
       "Communicating data science: A guide to presenti...                 0.052546   \n",
       "This Week in Data Science (April 18, 2017)                         0.041275   \n",
       "DataLayer Conference: Boost the performance of ...                 0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                      0.043310   \n",
       "...                                                                     ...   \n",
       "A look under the covers of PouchDB-find                            0.000000   \n",
       "A comparison of logistic regression and naive B...                 0.000000   \n",
       "What I Learned Implementing a Classifier from S...                 0.000000   \n",
       "Use dashDB with Spark                                              0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                 0.000000   \n",
       "\n",
       "                                                    Data Science Bowl 2017  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                0.000000   \n",
       "Communicating data science: A guide to presenti...                0.282969   \n",
       "This Week in Data Science (April 18, 2017)                        0.526122   \n",
       "DataLayer Conference: Boost the performance of ...                0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                     0.067692   \n",
       "...                                                                    ...   \n",
       "A look under the covers of PouchDB-find                           0.000000   \n",
       "A comparison of logistic regression and naive B...                0.000000   \n",
       "What I Learned Implementing a Classifier from S...                0.000000   \n",
       "Use dashDB with Spark                                             0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                0.000000   \n",
       "\n",
       "                                                    Using Apache Spark to predict attack vectors among billions of users and trillions of events  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000                                              \n",
       "Communicating data science: A guide to presenti...                                           0.000000                                              \n",
       "This Week in Data Science (April 18, 2017)                                                   0.000000                                              \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000                                              \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.170562                                              \n",
       "...                                                                                               ...                                              \n",
       "A look under the covers of PouchDB-find                                                      0.000000                                              \n",
       "A comparison of logistic regression and naive B...                                           0.000000                                              \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000                                              \n",
       "Use dashDB with Spark                                                                        0.142585                                              \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000                                              \n",
       "\n",
       "                                                    ...  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...  ...   \n",
       "Communicating data science: A guide to presenti...  ...   \n",
       "This Week in Data Science (April 18, 2017)          ...   \n",
       "DataLayer Conference: Boost the performance of ...  ...   \n",
       "Analyze NY Restaurant data using Spark in DSX       ...   \n",
       "...                                                 ...   \n",
       "A look under the covers of PouchDB-find             ...   \n",
       "A comparison of logistic regression and naive B...  ...   \n",
       "What I Learned Implementing a Classifier from S...  ...   \n",
       "Use dashDB with Spark                               ...   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels  ...   \n",
       "\n",
       "                                                    Mapping All the Things with Python – IBM Watson Data Lab – Medium  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000                   \n",
       "Communicating data science: A guide to presenti...                                           0.040063                   \n",
       "This Week in Data Science (April 18, 2017)                                                   0.031470                   \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000                   \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.033021                   \n",
       "...                                                                                               ...                   \n",
       "A look under the covers of PouchDB-find                                                      0.000000                   \n",
       "A comparison of logistic regression and naive B...                                           0.000000                   \n",
       "What I Learned Implementing a Classifier from S...                                           0.141363                   \n",
       "Use dashDB with Spark                                                                        0.000000                   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.130399                   \n",
       "\n",
       "                                                    Use IBM Data Science Experience to Read and Write Data Stored on Amazon S3  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000                            \n",
       "Communicating data science: A guide to presenti...                                           0.141384                            \n",
       "This Week in Data Science (April 18, 2017)                                                   0.111058                            \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000                            \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.052428                            \n",
       "...                                                                                               ...                            \n",
       "A look under the covers of PouchDB-find                                                      0.000000                            \n",
       "A comparison of logistic regression and naive B...                                           0.000000                            \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000                            \n",
       "Use dashDB with Spark                                                                        0.169739                            \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000                            \n",
       "\n",
       "                                                    Use IoT data in Streams Designer for billing and alerts  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.233189         \n",
       "Communicating data science: A guide to presenti...                                           0.043087         \n",
       "This Week in Data Science (April 18, 2017)                                                   0.033845         \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000         \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.035513         \n",
       "...                                                                                               ...         \n",
       "A look under the covers of PouchDB-find                                                      0.000000         \n",
       "A comparison of logistic regression and naive B...                                           0.000000         \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000         \n",
       "Use dashDB with Spark                                                                        0.229955         \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000         \n",
       "\n",
       "                                                    Mapping Points with Folium  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                         0.0   \n",
       "Communicating data science: A guide to presenti...                         0.0   \n",
       "This Week in Data Science (April 18, 2017)                                 0.0   \n",
       "DataLayer Conference: Boost the performance of ...                         0.0   \n",
       "Analyze NY Restaurant data using Spark in DSX                              0.0   \n",
       "...                                                                        ...   \n",
       "A look under the covers of PouchDB-find                                    0.0   \n",
       "A comparison of logistic regression and naive B...                         0.0   \n",
       "What I Learned Implementing a Classifier from S...                         0.0   \n",
       "Use dashDB with Spark                                                      0.0   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                         0.0   \n",
       "\n",
       "                                                    A Speed Guide To Redis Lua Scripting  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                              0.000000   \n",
       "Communicating data science: A guide to presenti...                              0.268218   \n",
       "This Week in Data Science (April 18, 2017)                                      0.000000   \n",
       "DataLayer Conference: Boost the performance of ...                              0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                   0.000000   \n",
       "...                                                                                  ...   \n",
       "A look under the covers of PouchDB-find                                         0.000000   \n",
       "A comparison of logistic regression and naive B...                              0.000000   \n",
       "What I Learned Implementing a Classifier from S...                              0.000000   \n",
       "Use dashDB with Spark                                                           0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                              0.000000   \n",
       "\n",
       "                                                    A look under the covers of PouchDB-find  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                      0.0   \n",
       "Communicating data science: A guide to presenti...                                      0.0   \n",
       "This Week in Data Science (April 18, 2017)                                              0.0   \n",
       "DataLayer Conference: Boost the performance of ...                                      0.0   \n",
       "Analyze NY Restaurant data using Spark in DSX                                           0.0   \n",
       "...                                                                                     ...   \n",
       "A look under the covers of PouchDB-find                                                 1.0   \n",
       "A comparison of logistic regression and naive B...                                      0.0   \n",
       "What I Learned Implementing a Classifier from S...                                      0.0   \n",
       "Use dashDB with Spark                                                                   0.0   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                      0.0   \n",
       "\n",
       "                                                    A comparison of logistic regression and naive Bayes   \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                                0.0      \n",
       "Communicating data science: A guide to presenti...                                                0.0      \n",
       "This Week in Data Science (April 18, 2017)                                                        0.0      \n",
       "DataLayer Conference: Boost the performance of ...                                                0.0      \n",
       "Analyze NY Restaurant data using Spark in DSX                                                     0.0      \n",
       "...                                                                                               ...      \n",
       "A look under the covers of PouchDB-find                                                           0.0      \n",
       "A comparison of logistic regression and naive B...                                                1.0      \n",
       "What I Learned Implementing a Classifier from S...                                                0.0      \n",
       "Use dashDB with Spark                                                                             0.0      \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                                0.0      \n",
       "\n",
       "                                                    What I Learned Implementing a Classifier from Scratch in Python · Jean-Nicholas Hould  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                            0.00000                                       \n",
       "Communicating data science: A guide to presenti...                                            0.00000                                       \n",
       "This Week in Data Science (April 18, 2017)                                                    0.00000                                       \n",
       "DataLayer Conference: Boost the performance of ...                                            0.00000                                       \n",
       "Analyze NY Restaurant data using Spark in DSX                                                 0.00000                                       \n",
       "...                                                                                               ...                                       \n",
       "A look under the covers of PouchDB-find                                                       0.00000                                       \n",
       "A comparison of logistic regression and naive B...                                            0.00000                                       \n",
       "What I Learned Implementing a Classifier from S...                                            1.00000                                       \n",
       "Use dashDB with Spark                                                                         0.00000                                       \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                            0.16529                                       \n",
       "\n",
       "                                                    Use dashDB with Spark  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...               0.000000   \n",
       "Communicating data science: A guide to presenti...               0.000000   \n",
       "This Week in Data Science (April 18, 2017)                       0.000000   \n",
       "DataLayer Conference: Boost the performance of ...               0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                    0.182155   \n",
       "...                                                                   ...   \n",
       "A look under the covers of PouchDB-find                          0.000000   \n",
       "A comparison of logistic regression and naive B...               0.000000   \n",
       "What I Learned Implementing a Classifier from S...               0.000000   \n",
       "Use dashDB with Spark                                            1.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels               0.000000   \n",
       "\n",
       "                                                    Jupyter Notebooks with Scala, Python, or R Kernels  \n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                            0.00000   \n",
       "Communicating data science: A guide to presenti...                                            0.00000   \n",
       "This Week in Data Science (April 18, 2017)                                                    0.00000   \n",
       "DataLayer Conference: Boost the performance of ...                                            0.00000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                                 0.00000   \n",
       "...                                                                                               ...   \n",
       "A look under the covers of PouchDB-find                                                       0.00000   \n",
       "A comparison of logistic regression and naive B...                                            0.00000   \n",
       "What I Learned Implementing a Classifier from S...                                            0.16529   \n",
       "Use dashDB with Spark                                                                         0.00000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                            1.00000   \n",
       "\n",
       "[1051 rows x 1051 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_df = build_similarity_model(df_content)\n",
    "cosine_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "27db1b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...        1\n",
       "1      1314.0       healthcare python streaming application demo        2\n",
       "2      1429.0         use deep learning for image classification        3\n",
       "3      1338.0          ml optimization using cognitive assistant        4\n",
       "4      1276.0          deploy your python model as a restful api        5"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5eef01e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>1434.0</th>\n",
       "      <th>1435.0</th>\n",
       "      <th>1436.0</th>\n",
       "      <th>1437.0</th>\n",
       "      <th>1439.0</th>\n",
       "      <th>1440.0</th>\n",
       "      <th>1441.0</th>\n",
       "      <th>1442.0</th>\n",
       "      <th>1443.0</th>\n",
       "      <th>1444.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0     2.0     4.0     8.0     9.0     12.0    14.0    15.0    \\\n",
       "user_id                                                                      \n",
       "1                0       0       0       0       0       0       0       0   \n",
       "2                0       0       0       0       0       0       0       0   \n",
       "3                0       0       0       0       0       1       0       0   \n",
       "\n",
       "article_id  16.0    18.0    ...  1434.0  1435.0  1436.0  1437.0  1439.0  \\\n",
       "user_id                     ...                                           \n",
       "1                0       0  ...       0       0       1       0       1   \n",
       "2                0       0  ...       0       0       0       0       0   \n",
       "3                0       0  ...       0       0       1       0       0   \n",
       "\n",
       "article_id  1440.0  1441.0  1442.0  1443.0  1444.0  \n",
       "user_id                                             \n",
       "1                0       0       0       0       0  \n",
       "2                0       0       0       0       0  \n",
       "3                0       0       0       0       0  \n",
       "\n",
       "[3 rows x 714 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pivot table from dfs user_id and article_id columns where 1s indicate an entry and 0 not\n",
    "df_new = df[['user_id', 'article_id']].pivot_table(index='user_id', columns='article_id', aggfunc=lambda x: 1, fill_value=0)\n",
    "df_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3dafa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    # Fill in the function here\n",
    "    user_item = df[['user_id', 'article_id']].pivot_table(index='user_id', columns='article_id', aggfunc=lambda x: 1, fill_value=0)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n",
    "\n",
    "user_item = create_user_item_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "563d1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    # Your code here\n",
    "    article_names = df[df['article_id'].isin(article_ids)]['title'].drop_duplicates().tolist()\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    \n",
    "    # Get the article IDs for the user, where interaction is 1\n",
    "    article_ids = user_item.columns[user_item.iloc[user_id-1] == 1].astype(str).tolist()\n",
    "    \n",
    "    # Get the article names using the article IDs\n",
    "    article_names = get_article_names(article_ids)\n",
    "    \n",
    "    return article_ids, article_names # return the ids and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "41d94a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232.0, 844.0, 1320.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['232.0', '844.0', '1320.0']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the articles the user has already seen\n",
    "user_article_ids = user_item.loc[20][user_item.loc[20] == 1].index.tolist()\n",
    "print(user_article_ids)\n",
    "\n",
    "article_ids, article_names = get_user_articles(20, user_item=user_item)\n",
    "article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "600e5587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_id'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0d71178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id\n",
       "1429.0    937\n",
       "1431.0    671\n",
       "1427.0    643\n",
       "1293.0    572\n",
       "1170.0    565\n",
       "1436.0    481\n",
       "43.0      460\n",
       "1185.0    442\n",
       "1368.0    418\n",
       "1305.0    413\n",
       "151.0     352\n",
       "1430.0    336\n",
       "1052.0    330\n",
       "1400.0    279\n",
       "390.0     270\n",
       "732.0     239\n",
       "109.0     198\n",
       "1391.0    191\n",
       "1183.0    168\n",
       "268.0     151\n",
       "981.0     130\n",
       "910.0     125\n",
       "525.0      85\n",
       "310.0      84\n",
       "329.0      65\n",
       "1439.0     59\n",
       "1406.0     58\n",
       "494.0      48\n",
       "768.0      28\n",
       "585.0      26\n",
       "968.0      26\n",
       "346.0      25\n",
       "1363.0     22\n",
       "1232.0     12\n",
       "668.0      12\n",
       "626.0      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_ids_seen, article_names_seen = get_user_articles(1, user_item=user_item)\n",
    "articles_seen = df[df['article_id'].astype(str).isin(article_ids_seen)]\n",
    "article_interactions = articles_seen['article_id'].value_counts()\n",
    "article_id_nr_1 = article_interactions.idxmax()\n",
    "article_id_nr_1 = float(article_id_nr_1)\n",
    "article_interactions\n",
    "#df.loc[article_ids_seen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c1bef1f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1200",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[257], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m article_title \u001b[38;5;241m=\u001b[39m df_content\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1200\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_full_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      2\u001b[0m article_title\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4236\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4234\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   4235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4236\u001b[0m     loc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   4239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1200"
     ]
    }
   ],
   "source": [
    "article_title = df_content.loc[1200][\"doc_full_name\"]\n",
    "article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9198d89e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1320.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1320",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[229], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m article_title \u001b[38;5;241m=\u001b[39m df_content\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1320.0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_full_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mxs(label, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4236\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4234\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   4235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4236\u001b[0m     loc \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   4239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 1320.0"
     ]
    }
   ],
   "source": [
    "article_title = df_content.loc[1320.0][\"doc_full_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d77a5d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['232.0', '844.0', '1320.0']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_ids_seen, _ = get_user_articles(20, user_item=user_item)\n",
    "article_ids_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3703a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recc(user_id, m=10, missing_articles=missing_articles):\n",
    "    \"\"\"\n",
    "    Recommend m most similar articles to the most popular article the user has interacted with,\n",
    "    excluding articles that are missing from df_content. Outputs both article_id and doc_full_name.\n",
    "    \n",
    "    Args:\n",
    "    user_id (int): The ID of the user for whom recommendations are being made.\n",
    "    m (int): The number of recommendations to generate. Default is 10.\n",
    "    missing_articles (list): A list of article_ids that should be excluded from the recommendations.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of recommended articles in the form of tuples (article_id, doc_full_name).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get article ids of the articles the user has seen\n",
    "    article_ids_seen, _ = get_user_articles(user_id, user_item=user_item)\n",
    "\n",
    "    # Filter the articles seen by the user, excluding missing articles in df_content\n",
    "    articles_seen = df[df['article_id'].astype(str).isin(article_ids_seen) & \n",
    "                       ~df['article_id'].astype(str).isin(missing_articles)]\n",
    "\n",
    "    # Check if any articles are left after filtering\n",
    "    if articles_seen.empty:\n",
    "        print(f\"User {user_id} has not seen any valid articles (excluding missing ones).\")\n",
    "        return []\n",
    "\n",
    "    # Rank articles seen by the user by the number of interactions\n",
    "    article_interactions = articles_seen['article_id'].value_counts()\n",
    "    article_id_nr_1 = article_interactions.idxmax()\n",
    "\n",
    "    # Get the article name of the most interacted article\n",
    "    article_name_nr_1 = df_content[df_content['article_id'] == article_id_nr_1]['doc_full_name'].values[0]\n",
    "\n",
    "    # Print user id and the article chosen for similarity comparison\n",
    "    print(f\"Recommendations for User ID: {user_id}\")\n",
    "    print(f\"Article used for similarity comparison (most interacted by user):\")\n",
    "    print(f\"  - Article ID: {article_id_nr_1}, Article Name: {article_name_nr_1}\")\n",
    "    \n",
    "    # Get the cosine similarity DataFrame using the build_similarity_model() function\n",
    "    cosine_sim_df = build_similarity_model(df_content)  # Assuming cosine_sim_df is built globally or from another source\n",
    "\n",
    "    # Find the most similar articles to the most popular one\n",
    "    sorted_similarity_scores = cosine_sim_df.loc[article_name_nr_1].sort_values(ascending=False)\n",
    "\n",
    "    # Drop the chosen article_id article from the list to avoid recommending the same article\n",
    "    sorted_similarity_scores = sorted_similarity_scores.drop(article_name_nr_1)\n",
    "\n",
    "    # Filter articles that the user has not seen, not missing, and take the top m recommendations\n",
    "    recommendations = []\n",
    "    \n",
    "    for similar_article_name in sorted_similarity_scores.index:\n",
    "        similar_article_id = df_content[df_content['doc_full_name'] == similar_article_name]['article_id'].values[0]\n",
    "\n",
    "        # Only recommend articles that the user has not seen and are not in missing_articles\n",
    "        if similar_article_id not in article_ids_seen and similar_article_id not in missing_articles:\n",
    "            recommendations.append((similar_article_id, similar_article_name))\n",
    "\n",
    "        # Stop when we have enough recommendations\n",
    "        if len(recommendations) >= m:\n",
    "            break\n",
    "\n",
    "    # Output the recommended articles\n",
    "    print(\"\\nRecommended Articles:\")\n",
    "    for article_id, article_name in recommendations:\n",
    "        print(f\"  - Article ID: {article_id}, Article Name: {article_name}\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "1c489243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User ID: 20\n",
      "Article used for similarity comparison (most interacted by user):\n",
      "  - Article ID: 844.0, Article Name: Use the Cloudant-Spark connector in Python notebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended Articles:\n",
      "  - Article ID: 264.0, Article Name: Introducing spark-cloudant, an open source Spark connector for Cloudant data\n",
      "  - Article ID: 934.0, Article Name: Load Cloudant Data in Apache Spark Using a Python Notebook\n",
      "  - Article ID: 1049.0, Article Name: Use dashDB with Spark\n",
      "  - Article ID: 776.0, Article Name: Your own weather forecast in a Python notebook\n",
      "  - Article ID: 953.0, Article Name: Simple Data Pipe connectors\n",
      "  - Article ID: 172.0, Article Name: Simple Data Pipe Connectors\n",
      "  - Article ID: 463.0, Article Name: What is Spark?\n",
      "  - Article ID: 560.0, Article Name: Load Cloudant Data in Apache Spark Using a Scala Notebook\n",
      "  - Article ID: 916.0, Article Name: Use the new Cloudant query\n",
      "  - Article ID: 161.0, Article Name: Use the Machine Learning Library in Spark\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('264.0',\n",
       "  'Introducing spark-cloudant, an open source Spark connector for Cloudant data'),\n",
       " ('934.0', 'Load Cloudant Data in Apache Spark Using a Python Notebook'),\n",
       " ('1049.0', 'Use dashDB with Spark'),\n",
       " ('776.0', 'Your own weather forecast in a Python notebook'),\n",
       " ('953.0', 'Simple Data Pipe connectors'),\n",
       " ('172.0', 'Simple Data Pipe Connectors'),\n",
       " ('463.0', 'What is Spark?'),\n",
       " ('560.0', 'Load Cloudant Data in Apache Spark Using a Scala Notebook'),\n",
       " ('916.0', 'Use the new Cloudant query'),\n",
       " ('161.0', 'Use the Machine Learning Library in Spark')]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_based_recc(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8c86ee58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Detect Malfunctioning IoT Sensors with Streaming Analytics</th>\n",
       "      <th>Communicating data science: A guide to presenting your work</th>\n",
       "      <th>This Week in Data Science (April 18, 2017)</th>\n",
       "      <th>DataLayer Conference: Boost the performance of your distributed database</th>\n",
       "      <th>Analyze NY Restaurant data using Spark in DSX</th>\n",
       "      <th>Browsing PostgreSQL Data with Compose</th>\n",
       "      <th>Upgrading your PostgreSQL to 9.5</th>\n",
       "      <th>Data Wrangling at Slack</th>\n",
       "      <th>Data Science Bowl 2017</th>\n",
       "      <th>Using Apache Spark to predict attack vectors among billions of users and trillions of events</th>\n",
       "      <th>...</th>\n",
       "      <th>Mapping All the Things with Python – IBM Watson Data Lab – Medium</th>\n",
       "      <th>Use IBM Data Science Experience to Read and Write Data Stored on Amazon S3</th>\n",
       "      <th>Use IoT data in Streams Designer for billing and alerts</th>\n",
       "      <th>Mapping Points with Folium</th>\n",
       "      <th>A Speed Guide To Redis Lua Scripting</th>\n",
       "      <th>A look under the covers of PouchDB-find</th>\n",
       "      <th>A comparison of logistic regression and naive Bayes</th>\n",
       "      <th>What I Learned Implementing a Classifier from Scratch in Python · Jean-Nicholas Hould</th>\n",
       "      <th>Use dashDB with Spark</th>\n",
       "      <th>Jupyter Notebooks with Scala, Python, or R Kernels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detect Malfunctioning IoT Sensors with Streaming Analytics</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communicating data science: A guide to presenting your work</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045340</td>\n",
       "      <td>0.087390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052546</td>\n",
       "      <td>0.282969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040063</td>\n",
       "      <td>0.141384</td>\n",
       "      <td>0.043087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This Week in Data Science (April 18, 2017)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>0.068645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041275</td>\n",
       "      <td>0.526122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031470</td>\n",
       "      <td>0.111058</td>\n",
       "      <td>0.033845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataLayer Conference: Boost the performance of your distributed database</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analyze NY Restaurant data using Spark in DSX</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045340</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>0.067692</td>\n",
       "      <td>0.170562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.052428</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A look under the covers of PouchDB-find</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A comparison of logistic regression and naive Bayes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What I Learned Implementing a Classifier from Scratch in Python · Jean-Nicholas Hould</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Use dashDB with Spark</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>0.229955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jupyter Notebooks with Scala, Python, or R Kernels</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 1051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Detect Malfunctioning IoT Sensors with Streaming Analytics  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                                1.0            \n",
       "Communicating data science: A guide to presenti...                                                0.0            \n",
       "This Week in Data Science (April 18, 2017)                                                        0.0            \n",
       "DataLayer Conference: Boost the performance of ...                                                0.0            \n",
       "Analyze NY Restaurant data using Spark in DSX                                                     0.0            \n",
       "...                                                                                               ...            \n",
       "A look under the covers of PouchDB-find                                                           0.0            \n",
       "A comparison of logistic regression and naive B...                                                0.0            \n",
       "What I Learned Implementing a Classifier from S...                                                0.0            \n",
       "Use dashDB with Spark                                                                             0.0            \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                                0.0            \n",
       "\n",
       "                                                    Communicating data science: A guide to presenting your work  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000             \n",
       "Communicating data science: A guide to presenti...                                           1.000000             \n",
       "This Week in Data Science (April 18, 2017)                                                   0.148876             \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000             \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.045340             \n",
       "...                                                                                               ...             \n",
       "A look under the covers of PouchDB-find                                                      0.000000             \n",
       "A comparison of logistic regression and naive B...                                           0.000000             \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000             \n",
       "Use dashDB with Spark                                                                        0.000000             \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000             \n",
       "\n",
       "                                                    This Week in Data Science (April 18, 2017)  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                    0.000000   \n",
       "Communicating data science: A guide to presenti...                                    0.148876   \n",
       "This Week in Data Science (April 18, 2017)                                            1.000000   \n",
       "DataLayer Conference: Boost the performance of ...                                    0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                         0.035614   \n",
       "...                                                                                        ...   \n",
       "A look under the covers of PouchDB-find                                               0.000000   \n",
       "A comparison of logistic regression and naive B...                                    0.000000   \n",
       "What I Learned Implementing a Classifier from S...                                    0.000000   \n",
       "Use dashDB with Spark                                                                 0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                    0.000000   \n",
       "\n",
       "                                                    DataLayer Conference: Boost the performance of your distributed database  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                                0.0                          \n",
       "Communicating data science: A guide to presenti...                                                0.0                          \n",
       "This Week in Data Science (April 18, 2017)                                                        0.0                          \n",
       "DataLayer Conference: Boost the performance of ...                                                1.0                          \n",
       "Analyze NY Restaurant data using Spark in DSX                                                     0.0                          \n",
       "...                                                                                               ...                          \n",
       "A look under the covers of PouchDB-find                                                           0.0                          \n",
       "A comparison of logistic regression and naive B...                                                0.0                          \n",
       "What I Learned Implementing a Classifier from S...                                                0.0                          \n",
       "Use dashDB with Spark                                                                             0.0                          \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                                0.0                          \n",
       "\n",
       "                                                    Analyze NY Restaurant data using Spark in DSX  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                       0.000000   \n",
       "Communicating data science: A guide to presenti...                                       0.045340   \n",
       "This Week in Data Science (April 18, 2017)                                               0.035614   \n",
       "DataLayer Conference: Boost the performance of ...                                       0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                            1.000000   \n",
       "...                                                                                           ...   \n",
       "A look under the covers of PouchDB-find                                                  0.000000   \n",
       "A comparison of logistic regression and naive B...                                       0.000000   \n",
       "What I Learned Implementing a Classifier from S...                                       0.000000   \n",
       "Use dashDB with Spark                                                                    0.182155   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                       0.000000   \n",
       "\n",
       "                                                    Browsing PostgreSQL Data with Compose  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                               0.000000   \n",
       "Communicating data science: A guide to presenti...                               0.087390   \n",
       "This Week in Data Science (April 18, 2017)                                       0.068645   \n",
       "DataLayer Conference: Boost the performance of ...                               0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                    0.072029   \n",
       "...                                                                                   ...   \n",
       "A look under the covers of PouchDB-find                                          0.000000   \n",
       "A comparison of logistic regression and naive B...                               0.000000   \n",
       "What I Learned Implementing a Classifier from S...                               0.000000   \n",
       "Use dashDB with Spark                                                            0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                               0.000000   \n",
       "\n",
       "                                                    Upgrading your PostgreSQL to 9.5  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                               0.0   \n",
       "Communicating data science: A guide to presenti...                               0.0   \n",
       "This Week in Data Science (April 18, 2017)                                       0.0   \n",
       "DataLayer Conference: Boost the performance of ...                               0.0   \n",
       "Analyze NY Restaurant data using Spark in DSX                                    0.0   \n",
       "...                                                                              ...   \n",
       "A look under the covers of PouchDB-find                                          0.0   \n",
       "A comparison of logistic regression and naive B...                               0.0   \n",
       "What I Learned Implementing a Classifier from S...                               0.0   \n",
       "Use dashDB with Spark                                                            0.0   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                               0.0   \n",
       "\n",
       "                                                    Data Wrangling at Slack  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                 0.000000   \n",
       "Communicating data science: A guide to presenti...                 0.052546   \n",
       "This Week in Data Science (April 18, 2017)                         0.041275   \n",
       "DataLayer Conference: Boost the performance of ...                 0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                      0.043310   \n",
       "...                                                                     ...   \n",
       "A look under the covers of PouchDB-find                            0.000000   \n",
       "A comparison of logistic regression and naive B...                 0.000000   \n",
       "What I Learned Implementing a Classifier from S...                 0.000000   \n",
       "Use dashDB with Spark                                              0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                 0.000000   \n",
       "\n",
       "                                                    Data Science Bowl 2017  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                0.000000   \n",
       "Communicating data science: A guide to presenti...                0.282969   \n",
       "This Week in Data Science (April 18, 2017)                        0.526122   \n",
       "DataLayer Conference: Boost the performance of ...                0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                     0.067692   \n",
       "...                                                                    ...   \n",
       "A look under the covers of PouchDB-find                           0.000000   \n",
       "A comparison of logistic regression and naive B...                0.000000   \n",
       "What I Learned Implementing a Classifier from S...                0.000000   \n",
       "Use dashDB with Spark                                             0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                0.000000   \n",
       "\n",
       "                                                    Using Apache Spark to predict attack vectors among billions of users and trillions of events  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000                                              \n",
       "Communicating data science: A guide to presenti...                                           0.000000                                              \n",
       "This Week in Data Science (April 18, 2017)                                                   0.000000                                              \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000                                              \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.170562                                              \n",
       "...                                                                                               ...                                              \n",
       "A look under the covers of PouchDB-find                                                      0.000000                                              \n",
       "A comparison of logistic regression and naive B...                                           0.000000                                              \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000                                              \n",
       "Use dashDB with Spark                                                                        0.142585                                              \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000                                              \n",
       "\n",
       "                                                    ...  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...  ...   \n",
       "Communicating data science: A guide to presenti...  ...   \n",
       "This Week in Data Science (April 18, 2017)          ...   \n",
       "DataLayer Conference: Boost the performance of ...  ...   \n",
       "Analyze NY Restaurant data using Spark in DSX       ...   \n",
       "...                                                 ...   \n",
       "A look under the covers of PouchDB-find             ...   \n",
       "A comparison of logistic regression and naive B...  ...   \n",
       "What I Learned Implementing a Classifier from S...  ...   \n",
       "Use dashDB with Spark                               ...   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels  ...   \n",
       "\n",
       "                                                    Mapping All the Things with Python – IBM Watson Data Lab – Medium  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000                   \n",
       "Communicating data science: A guide to presenti...                                           0.040063                   \n",
       "This Week in Data Science (April 18, 2017)                                                   0.031470                   \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000                   \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.033021                   \n",
       "...                                                                                               ...                   \n",
       "A look under the covers of PouchDB-find                                                      0.000000                   \n",
       "A comparison of logistic regression and naive B...                                           0.000000                   \n",
       "What I Learned Implementing a Classifier from S...                                           0.141363                   \n",
       "Use dashDB with Spark                                                                        0.000000                   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.130399                   \n",
       "\n",
       "                                                    Use IBM Data Science Experience to Read and Write Data Stored on Amazon S3  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.000000                            \n",
       "Communicating data science: A guide to presenti...                                           0.141384                            \n",
       "This Week in Data Science (April 18, 2017)                                                   0.111058                            \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000                            \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.052428                            \n",
       "...                                                                                               ...                            \n",
       "A look under the covers of PouchDB-find                                                      0.000000                            \n",
       "A comparison of logistic regression and naive B...                                           0.000000                            \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000                            \n",
       "Use dashDB with Spark                                                                        0.169739                            \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000                            \n",
       "\n",
       "                                                    Use IoT data in Streams Designer for billing and alerts  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                           0.233189         \n",
       "Communicating data science: A guide to presenti...                                           0.043087         \n",
       "This Week in Data Science (April 18, 2017)                                                   0.033845         \n",
       "DataLayer Conference: Boost the performance of ...                                           0.000000         \n",
       "Analyze NY Restaurant data using Spark in DSX                                                0.035513         \n",
       "...                                                                                               ...         \n",
       "A look under the covers of PouchDB-find                                                      0.000000         \n",
       "A comparison of logistic regression and naive B...                                           0.000000         \n",
       "What I Learned Implementing a Classifier from S...                                           0.000000         \n",
       "Use dashDB with Spark                                                                        0.229955         \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                           0.000000         \n",
       "\n",
       "                                                    Mapping Points with Folium  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                         0.0   \n",
       "Communicating data science: A guide to presenti...                         0.0   \n",
       "This Week in Data Science (April 18, 2017)                                 0.0   \n",
       "DataLayer Conference: Boost the performance of ...                         0.0   \n",
       "Analyze NY Restaurant data using Spark in DSX                              0.0   \n",
       "...                                                                        ...   \n",
       "A look under the covers of PouchDB-find                                    0.0   \n",
       "A comparison of logistic regression and naive B...                         0.0   \n",
       "What I Learned Implementing a Classifier from S...                         0.0   \n",
       "Use dashDB with Spark                                                      0.0   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                         0.0   \n",
       "\n",
       "                                                    A Speed Guide To Redis Lua Scripting  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                              0.000000   \n",
       "Communicating data science: A guide to presenti...                              0.268218   \n",
       "This Week in Data Science (April 18, 2017)                                      0.000000   \n",
       "DataLayer Conference: Boost the performance of ...                              0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                   0.000000   \n",
       "...                                                                                  ...   \n",
       "A look under the covers of PouchDB-find                                         0.000000   \n",
       "A comparison of logistic regression and naive B...                              0.000000   \n",
       "What I Learned Implementing a Classifier from S...                              0.000000   \n",
       "Use dashDB with Spark                                                           0.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                              0.000000   \n",
       "\n",
       "                                                    A look under the covers of PouchDB-find  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                      0.0   \n",
       "Communicating data science: A guide to presenti...                                      0.0   \n",
       "This Week in Data Science (April 18, 2017)                                              0.0   \n",
       "DataLayer Conference: Boost the performance of ...                                      0.0   \n",
       "Analyze NY Restaurant data using Spark in DSX                                           0.0   \n",
       "...                                                                                     ...   \n",
       "A look under the covers of PouchDB-find                                                 1.0   \n",
       "A comparison of logistic regression and naive B...                                      0.0   \n",
       "What I Learned Implementing a Classifier from S...                                      0.0   \n",
       "Use dashDB with Spark                                                                   0.0   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                      0.0   \n",
       "\n",
       "                                                    A comparison of logistic regression and naive Bayes   \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                                0.0      \n",
       "Communicating data science: A guide to presenti...                                                0.0      \n",
       "This Week in Data Science (April 18, 2017)                                                        0.0      \n",
       "DataLayer Conference: Boost the performance of ...                                                0.0      \n",
       "Analyze NY Restaurant data using Spark in DSX                                                     0.0      \n",
       "...                                                                                               ...      \n",
       "A look under the covers of PouchDB-find                                                           0.0      \n",
       "A comparison of logistic regression and naive B...                                                1.0      \n",
       "What I Learned Implementing a Classifier from S...                                                0.0      \n",
       "Use dashDB with Spark                                                                             0.0      \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                                0.0      \n",
       "\n",
       "                                                    What I Learned Implementing a Classifier from Scratch in Python · Jean-Nicholas Hould  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                            0.00000                                       \n",
       "Communicating data science: A guide to presenti...                                            0.00000                                       \n",
       "This Week in Data Science (April 18, 2017)                                                    0.00000                                       \n",
       "DataLayer Conference: Boost the performance of ...                                            0.00000                                       \n",
       "Analyze NY Restaurant data using Spark in DSX                                                 0.00000                                       \n",
       "...                                                                                               ...                                       \n",
       "A look under the covers of PouchDB-find                                                       0.00000                                       \n",
       "A comparison of logistic regression and naive B...                                            0.00000                                       \n",
       "What I Learned Implementing a Classifier from S...                                            1.00000                                       \n",
       "Use dashDB with Spark                                                                         0.00000                                       \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                            0.16529                                       \n",
       "\n",
       "                                                    Use dashDB with Spark  \\\n",
       "Detect Malfunctioning IoT Sensors with Streamin...               0.000000   \n",
       "Communicating data science: A guide to presenti...               0.000000   \n",
       "This Week in Data Science (April 18, 2017)                       0.000000   \n",
       "DataLayer Conference: Boost the performance of ...               0.000000   \n",
       "Analyze NY Restaurant data using Spark in DSX                    0.182155   \n",
       "...                                                                   ...   \n",
       "A look under the covers of PouchDB-find                          0.000000   \n",
       "A comparison of logistic regression and naive B...               0.000000   \n",
       "What I Learned Implementing a Classifier from S...               0.000000   \n",
       "Use dashDB with Spark                                            1.000000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels               0.000000   \n",
       "\n",
       "                                                    Jupyter Notebooks with Scala, Python, or R Kernels  \n",
       "Detect Malfunctioning IoT Sensors with Streamin...                                            0.00000   \n",
       "Communicating data science: A guide to presenti...                                            0.00000   \n",
       "This Week in Data Science (April 18, 2017)                                                    0.00000   \n",
       "DataLayer Conference: Boost the performance of ...                                            0.00000   \n",
       "Analyze NY Restaurant data using Spark in DSX                                                 0.00000   \n",
       "...                                                                                               ...   \n",
       "A look under the covers of PouchDB-find                                                       0.00000   \n",
       "A comparison of logistic regression and naive B...                                            0.00000   \n",
       "What I Learned Implementing a Classifier from S...                                            0.16529   \n",
       "Use dashDB with Spark                                                                         0.00000   \n",
       "Jupyter Notebooks with Scala, Python, or R Kernels                                            1.00000   \n",
       "\n",
       "[1051 rows x 1051 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_title = df_content.loc[20][\"doc_full_name\"]\n",
    "    # Choose the row with the article_title in X\n",
    "X.loc[article_title]\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e7d8c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    Working interactively with RStudio and noteboo...\n",
       "40    Ensemble Learning to Improve Machine Learning ...\n",
       "Name: doc_full_name, dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_title = df_content.loc[[20.0, 40]][\"doc_full_name\"]\n",
    "article_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe32ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
